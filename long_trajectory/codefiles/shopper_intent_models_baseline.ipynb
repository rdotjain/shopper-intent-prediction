{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-27 13:39:27.186281: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.tree import *\n",
    "from sklearn.linear_model import *\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import re\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_dataframes = '/Users/nitanshjain/Documents/Projects/Shopper_Intent_Prediction/shopper-intent-prediction/long_trajectory/subsamples/'\n",
    "directory_features = '/Users/nitanshjain/Documents/Projects/Shopper_Intent_Prediction/shopper-intent-prediction/long_trajectory/features/'\n",
    "\n",
    "def get_sample_df(directory=directory_dataframes):\n",
    "    list_dataframes = []\n",
    "    for filename in os.listdir(directory):\n",
    "        f = os.path.join(directory, filename)\n",
    "        if os.path.isfile(f):\n",
    "            list_dataframes.append(pd.read_csv(f))\n",
    "            \n",
    "    return list_dataframes\n",
    "\n",
    "def get_features(regex_str, directory=directory_features):\n",
    "    regex = re.compile('/Users/nitanshjain/Documents/Projects/Shopper_Intent_Prediction/shopper-intent-prediction/long_trajectory/features/{}'.format(regex_str))\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        f = os.path.join(directory, filename)\n",
    "        if regex.match(f):\n",
    "            file1 = open(f,\"r+\")\n",
    "            feat_list = file1.read().splitlines()\n",
    "            \n",
    "            #txt file converts everything to string, so we need to convert it back to list\n",
    "            for val in feat_list:\n",
    "                #adding ; to be used a separator for list\n",
    "                new_val = val.replace('y','y;').replace(') ','); ')\n",
    "                feat_list[feat_list.index(val)] = new_val\n",
    "                \n",
    "    for val in feat_list:\n",
    "        #separating the string into a list of features\n",
    "        new_val = val.split('; ')\n",
    "        feat_list[feat_list.index(val)] = new_val\n",
    "        \n",
    "    return feat_list\n",
    "\n",
    "list_sample_dataframes = get_sample_df(directory_dataframes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models to be used for baseline\n",
    "<li>Logistic Regression</li>\n",
    "<li>Random Forest</li>\n",
    "<li>Support Vector Machine</li>\n",
    "<li>XGB</li>\n",
    "<li>Neural Network</li>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_feat_list_10 = get_features('mi_feat_list_10*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7548076923076923, 0.7980769230769231, 0.8269230769230769, 0.8125, 0.8173076923076923, 0.8125, 0.8125, 0.8269230769230769, 0.8173076923076923, 0.8076923076923077]\n",
      "[0.76056338028169, 0.7941176470588236, 0.8181818181818181, 0.8059701492537313, 0.8118811881188118, 0.8078817733990148, 0.8059701492537313, 0.8181818181818181, 0.81, 0.801980198019802]\n",
      "[0.7548076923076924, 0.798076923076923, 0.8269230769230769, 0.8125, 0.8173076923076923, 0.8124999999999999, 0.8125, 0.8269230769230769, 0.8173076923076923, 0.8076923076923077]\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "accuracy_list = []\n",
    "f1_score_list = []\n",
    "auc_list = []\n",
    "for sample, feat in zip(list_sample_dataframes, mi_feat_list_10):\n",
    "    \n",
    "    x = sample[feat]\n",
    "    y = sample['conversion_class']\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    # print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "    lr.fit(x_train, y_train)\n",
    "    y_pred = lr.predict(x_test)\n",
    "    accuracy_list.append(accuracy_score(y_test, y_pred))\n",
    "    f1_score_list.append(f1_score(y_test, y_pred))\n",
    "    auc_list.append(roc_auc_score(y_test, y_pred))\n",
    "\n",
    "print(accuracy_list)\n",
    "print(f1_score_list) \n",
    "print(auc_list)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8269230769230769\n",
      "0.8181818181818181\n",
      "0.8269230769230769\n"
     ]
    }
   ],
   "source": [
    "print(max(accuracy_list))\n",
    "print(max(f1_score_list))\n",
    "print(max(auc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Shopper_Intent_Prediction-jr_Cp9Sf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
