{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mcdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3600, 16)\n",
      "Index(['length_text', 'samples', 'models', 'percentiles', 'mi_accuracy',\n",
      "       'mi_f1_score', 'mi_auc', 'mrmr_accuracy', 'mrmr_f1_score', 'mrmr_auc',\n",
      "       'mi_mrmr_accuracy', 'mi_mrmr_f1_score', 'mi_mrmr_auc', 'pca_accuracy',\n",
      "       'pca_f1_score', 'pca_auc'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length_text</th>\n",
       "      <th>samples</th>\n",
       "      <th>models</th>\n",
       "      <th>percentiles</th>\n",
       "      <th>mi_accuracy</th>\n",
       "      <th>mi_f1_score</th>\n",
       "      <th>mi_auc</th>\n",
       "      <th>mrmr_accuracy</th>\n",
       "      <th>mrmr_f1_score</th>\n",
       "      <th>mrmr_auc</th>\n",
       "      <th>mi_mrmr_accuracy</th>\n",
       "      <th>mi_mrmr_f1_score</th>\n",
       "      <th>mi_mrmr_auc</th>\n",
       "      <th>pca_accuracy</th>\n",
       "      <th>pca_f1_score</th>\n",
       "      <th>pca_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>subsample_5_v2.csv</td>\n",
       "      <td>ft_transformer</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7137</td>\n",
       "      <td>0.6516</td>\n",
       "      <td>0.7512</td>\n",
       "      <td>0.6785</td>\n",
       "      <td>0.6272</td>\n",
       "      <td>0.7372</td>\n",
       "      <td>0.6918</td>\n",
       "      <td>0.6256</td>\n",
       "      <td>0.7413</td>\n",
       "      <td>0.6928</td>\n",
       "      <td>0.6275</td>\n",
       "      <td>0.7396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>subsample_9_v2.csv</td>\n",
       "      <td>ft_transformer</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7137</td>\n",
       "      <td>0.6596</td>\n",
       "      <td>0.7584</td>\n",
       "      <td>0.6891</td>\n",
       "      <td>0.6465</td>\n",
       "      <td>0.7507</td>\n",
       "      <td>0.7157</td>\n",
       "      <td>0.6532</td>\n",
       "      <td>0.7420</td>\n",
       "      <td>0.7004</td>\n",
       "      <td>0.6334</td>\n",
       "      <td>0.7517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>subsample_3_v2.csv</td>\n",
       "      <td>ft_transformer</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7017</td>\n",
       "      <td>0.6347</td>\n",
       "      <td>0.7416</td>\n",
       "      <td>0.7054</td>\n",
       "      <td>0.6457</td>\n",
       "      <td>0.7446</td>\n",
       "      <td>0.6931</td>\n",
       "      <td>0.6254</td>\n",
       "      <td>0.7414</td>\n",
       "      <td>0.6772</td>\n",
       "      <td>0.6346</td>\n",
       "      <td>0.7313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>subsample_6_v2.csv</td>\n",
       "      <td>ft_transformer</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7004</td>\n",
       "      <td>0.6328</td>\n",
       "      <td>0.7537</td>\n",
       "      <td>0.7067</td>\n",
       "      <td>0.6453</td>\n",
       "      <td>0.7479</td>\n",
       "      <td>0.6894</td>\n",
       "      <td>0.6211</td>\n",
       "      <td>0.7548</td>\n",
       "      <td>0.7014</td>\n",
       "      <td>0.6386</td>\n",
       "      <td>0.7520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>subsample_7_v2.csv</td>\n",
       "      <td>ft_transformer</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7090</td>\n",
       "      <td>0.6416</td>\n",
       "      <td>0.7523</td>\n",
       "      <td>0.6921</td>\n",
       "      <td>0.6769</td>\n",
       "      <td>0.7460</td>\n",
       "      <td>0.6858</td>\n",
       "      <td>0.6756</td>\n",
       "      <td>0.7324</td>\n",
       "      <td>0.6954</td>\n",
       "      <td>0.6721</td>\n",
       "      <td>0.7495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   length_text             samples          models  percentiles  mi_accuracy  \\\n",
       "0            8  subsample_5_v2.csv  ft_transformer           10       0.7137   \n",
       "1            8  subsample_9_v2.csv  ft_transformer           10       0.7137   \n",
       "2            8  subsample_3_v2.csv  ft_transformer           10       0.7017   \n",
       "3            8  subsample_6_v2.csv  ft_transformer           10       0.7004   \n",
       "4            8  subsample_7_v2.csv  ft_transformer           10       0.7090   \n",
       "\n",
       "   mi_f1_score  mi_auc  mrmr_accuracy  mrmr_f1_score  mrmr_auc  \\\n",
       "0       0.6516  0.7512         0.6785         0.6272    0.7372   \n",
       "1       0.6596  0.7584         0.6891         0.6465    0.7507   \n",
       "2       0.6347  0.7416         0.7054         0.6457    0.7446   \n",
       "3       0.6328  0.7537         0.7067         0.6453    0.7479   \n",
       "4       0.6416  0.7523         0.6921         0.6769    0.7460   \n",
       "\n",
       "   mi_mrmr_accuracy  mi_mrmr_f1_score  mi_mrmr_auc  pca_accuracy  \\\n",
       "0            0.6918            0.6256       0.7413        0.6928   \n",
       "1            0.7157            0.6532       0.7420        0.7004   \n",
       "2            0.6931            0.6254       0.7414        0.6772   \n",
       "3            0.6894            0.6211       0.7548        0.7014   \n",
       "4            0.6858            0.6756       0.7324        0.6954   \n",
       "\n",
       "   pca_f1_score  pca_auc  \n",
       "0        0.6275   0.7396  \n",
       "1        0.6334   0.7517  \n",
       "2        0.6346   0.7313  \n",
       "3        0.6386   0.7520  \n",
       "4        0.6721   0.7495  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shopper_df = pd.read_csv('/Users/nitanshjain/Documents/Projects/Shopper_Intent_Prediction/shopper-intent-prediction/topsis_data/topsis_short.csv')\n",
    "print(shopper_df.shape)\n",
    "print(shopper_df.columns)\n",
    "shopper_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length_text\n",
      "8     360\n",
      "9     360\n",
      "10    360\n",
      "11    360\n",
      "12    360\n",
      "13    360\n",
      "14    360\n",
      "15    360\n",
      "16    360\n",
      "17    360\n",
      "Name: count, dtype: int64\n",
      "models\n",
      "ft_transformer    600\n",
      "lr                600\n",
      "rfc               600\n",
      "xgbc              600\n",
      "lgbm              600\n",
      "svm               600\n",
      "Name: count, dtype: int64\n",
      "percentiles\n",
      "10    600\n",
      "20    600\n",
      "30    600\n",
      "50    600\n",
      "75    600\n",
      "90    600\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(shopper_df.length_text.value_counts())\n",
    "print(shopper_df.models.value_counts())\n",
    "print(shopper_df.percentiles.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mi_accuracy', 'mi_f1_score', 'mi_auc', 'mrmr_accuracy',\n",
       "       'mrmr_f1_score', 'mrmr_auc', 'mi_mrmr_accuracy', 'mi_mrmr_f1_score',\n",
       "       'mi_mrmr_auc', 'pca_accuracy', 'pca_f1_score', 'pca_auc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting all columns that have a float64 type\n",
    "shopper_df_float = shopper_df.select_dtypes(include=['float64']).columns\n",
    "shopper_df_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           model1 model2 model3 model4 model5 model6  percentiles\n",
      "0  ft_transformer    svm   lgbm   xgbc    rfc     lr           10\n",
      "1  ft_transformer    svm   lgbm     lr   xgbc    rfc           20\n",
      "2  ft_transformer    svm   lgbm   xgbc     lr    rfc           30\n",
      "3  ft_transformer     lr    svm   lgbm   xgbc    rfc           50\n",
      "4  ft_transformer     lr    svm   lgbm    rfc   xgbc           75\n",
      "5  ft_transformer     lr   lgbm    svm   xgbc    rfc           90\n",
      "           model1 model2 model3 model4 model5 model6  percentiles\n",
      "0  ft_transformer    svm   xgbc   lgbm    rfc     lr           10\n",
      "1  ft_transformer    svm   lgbm    rfc   xgbc     lr           20\n",
      "2  ft_transformer    svm   xgbc   lgbm     lr    rfc           30\n",
      "3  ft_transformer    svm   lgbm     lr   xgbc    rfc           50\n",
      "4  ft_transformer   lgbm    svm   xgbc     lr    rfc           75\n",
      "5  ft_transformer    svm     lr   lgbm   xgbc    rfc           90\n",
      "           model1 model2 model3 model4 model5 model6  percentiles\n",
      "0  ft_transformer    svm   lgbm   xgbc    rfc     lr           10\n",
      "1  ft_transformer    svm    rfc   lgbm   xgbc     lr           20\n",
      "2  ft_transformer    svm    rfc   lgbm     lr   xgbc           30\n",
      "3  ft_transformer    svm    rfc     lr   lgbm   xgbc           50\n",
      "4  ft_transformer    svm    rfc     lr   lgbm   xgbc           75\n",
      "5  ft_transformer    svm   lgbm    rfc     lr   xgbc           90\n",
      "           model1 model2 model3 model4 model5 model6  percentiles\n",
      "0  ft_transformer    svm    rfc   lgbm   xgbc     lr           10\n",
      "1  ft_transformer    svm   lgbm    rfc   xgbc     lr           20\n",
      "2  ft_transformer    svm   lgbm    rfc   xgbc     lr           30\n",
      "3  ft_transformer    svm    rfc     lr   lgbm   xgbc           50\n",
      "4  ft_transformer    svm    rfc   lgbm     lr   xgbc           75\n",
      "5  ft_transformer    svm   lgbm    rfc     lr   xgbc           90\n",
      "           model1 model2 model3 model4 model5 model6  percentiles\n",
      "0  ft_transformer    svm   lgbm    rfc   xgbc     lr           10\n",
      "1  ft_transformer    svm   lgbm   xgbc    rfc     lr           20\n",
      "2  ft_transformer   lgbm    svm    rfc   xgbc     lr           30\n",
      "3  ft_transformer   lgbm    svm   xgbc    rfc     lr           50\n",
      "4  ft_transformer   lgbm    svm    rfc   xgbc     lr           75\n",
      "5  ft_transformer   lgbm    svm   xgbc    rfc     lr           90\n",
      "           model1 model2 model3 model4 model5 model6  percentiles\n",
      "0  ft_transformer    svm    rfc   lgbm   xgbc     lr           10\n",
      "1  ft_transformer    svm   lgbm    rfc   xgbc     lr           20\n",
      "2  ft_transformer    svm    rfc   lgbm   xgbc     lr           30\n",
      "3  ft_transformer    svm   lgbm    rfc   xgbc     lr           50\n",
      "4  ft_transformer    svm   lgbm    rfc   xgbc     lr           75\n",
      "5  ft_transformer    svm   lgbm    rfc   xgbc     lr           90\n",
      "           model1 model2 model3 model4 model5 model6  percentiles\n",
      "0  ft_transformer    svm   lgbm    rfc   xgbc     lr           10\n",
      "1  ft_transformer    svm   lgbm    rfc   xgbc     lr           20\n",
      "2  ft_transformer    svm   lgbm    rfc   xgbc     lr           30\n",
      "3  ft_transformer    svm   lgbm    rfc   xgbc     lr           50\n",
      "4  ft_transformer    svm   lgbm    rfc   xgbc     lr           75\n",
      "5  ft_transformer    svm   lgbm   xgbc    rfc     lr           90\n",
      "           model1 model2 model3 model4 model5 model6  percentiles\n",
      "0  ft_transformer    svm   lgbm   xgbc    rfc     lr           10\n",
      "1  ft_transformer    svm   lgbm    rfc   xgbc     lr           20\n",
      "2  ft_transformer    svm   lgbm    rfc   xgbc     lr           30\n",
      "3  ft_transformer    svm   lgbm    rfc   xgbc     lr           50\n",
      "4  ft_transformer    svm   lgbm    rfc   xgbc     lr           75\n",
      "5  ft_transformer   lgbm    svm    rfc   xgbc     lr           90\n",
      "           model1 model2 model3 model4 model5 model6  percentiles\n",
      "0  ft_transformer    svm   lgbm   xgbc    rfc     lr           10\n",
      "1  ft_transformer    svm   lgbm    rfc   xgbc     lr           20\n",
      "2  ft_transformer    svm   lgbm    rfc   xgbc     lr           30\n",
      "3  ft_transformer    svm    rfc   lgbm   xgbc     lr           50\n",
      "4  ft_transformer    svm    rfc   lgbm   xgbc     lr           75\n",
      "5  ft_transformer    svm    rfc   lgbm   xgbc     lr           90\n",
      "           model1 model2 model3 model4 model5 model6  percentiles\n",
      "0  ft_transformer    svm   lgbm    rfc   xgbc     lr           10\n",
      "1  ft_transformer    svm   lgbm    rfc   xgbc     lr           20\n",
      "2  ft_transformer    svm   lgbm    rfc   xgbc     lr           30\n",
      "3  ft_transformer    svm    rfc   lgbm   xgbc     lr           50\n",
      "4  ft_transformer    svm   lgbm    rfc   xgbc     lr           75\n",
      "5  ft_transformer    svm   lgbm    rfc   xgbc     lr           90\n"
     ]
    }
   ],
   "source": [
    "def mean_models(length, df=shopper_df): \n",
    "    percentiles_list = [10, 20, 30, 50, 75, 90]\n",
    "    models_list = ['ft_transformer', 'lr', 'rfc', 'xgbc', 'lgbm', 'svm']\n",
    "    all_df = list()\n",
    "    \n",
    "    for j in percentiles_list:\n",
    "        means = list()\n",
    "        for i in models_list:\n",
    "            model = df[(df.percentiles == j) & (df.models == i) & (df.length_text == length)]\n",
    "            # print(model)\n",
    "            mean_val = list(model[shopper_df_float].mean())\n",
    "            means.append(mean_val)\n",
    "        means_df = pd.DataFrame(means, columns=shopper_df_float).reset_index()\n",
    "        means_df['models_name'] = pd.Series(['ft_transformer', 'lr', 'rfc', 'xgbc', 'lgbm', 'svm'])\n",
    "        means_df['percentiles_name'] = pd.Series([j] * 6)\n",
    "        # print(means_df.head())\n",
    "        all_df.append(means_df)\n",
    "        \n",
    "    ranks_model_per_percentile = list()\n",
    "    for i in all_df:\n",
    "        i.drop(['index', 'models_name', 'percentiles_name'], axis=1, inplace=True)\n",
    "        ranks_model_per_percentile.append(mcdm.rank(i.to_numpy(), s_method='TOPSIS', alt_names=models_list))\n",
    "        \n",
    "    best_models = list()\n",
    "    for val in ranks_model_per_percentile:\n",
    "        best_models_per_percentile = list()\n",
    "        # print(val)\n",
    "        for i in val:\n",
    "                best_models_per_percentile.append(i[0])\n",
    "                \n",
    "        best_models.append(best_models_per_percentile)\n",
    "        \n",
    "    models_df = pd.DataFrame(best_models, columns=['model1', 'model2', 'model3', 'model4', 'model5', 'model6'])\n",
    "    models_df['percentiles'] = pd.Series([10, 20, 30, 50, 75, 90])\n",
    "    return models_df\n",
    "\n",
    "best_models_8 = mean_models(8)\n",
    "best_models_9 = mean_models(9)\n",
    "best_models_10 = mean_models(10)\n",
    "best_models_11 = mean_models(11)\n",
    "best_models_12 = mean_models(12)\n",
    "best_models_13 = mean_models(13)\n",
    "best_models_14 = mean_models(14)\n",
    "best_models_15 = mean_models(15)\n",
    "best_models_16 = mean_models(16)\n",
    "best_models_17 = mean_models(17)\n",
    "\n",
    "print(best_models_8)\n",
    "print(best_models_9)\n",
    "print(best_models_10)\n",
    "print(best_models_11)\n",
    "print(best_models_12)\n",
    "print(best_models_13)\n",
    "print(best_models_14)\n",
    "print(best_models_15)\n",
    "print(best_models_16)\n",
    "print(best_models_17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   per1  per2  per3  per4  per5  per6          models\n",
      "0    30    75    20    50    90    10  ft_transformer\n",
      "1    75    90    50    30    20    10              lr\n",
      "2    50    75    90    20    30    10             rfc\n",
      "3    50    30    90    20    75    10            xgbc\n",
      "4    50    90    75    30    20    10            lgbm\n",
      "5    50    30    20    90    75    10             svm\n",
      "   per1  per2  per3  per4  per5  per6          models\n",
      "0    50    30    90    75    20    10  ft_transformer\n",
      "1    50    75    90    30    20    10              lr\n",
      "2    75    90    50    30    20    10             rfc\n",
      "3    75    50    90    30    20    10            xgbc\n",
      "4    75    50    90    30    20    10            lgbm\n",
      "5    30    75    50    20    90    10             svm\n",
      "   per1  per2  per3  per4  per5  per6          models\n",
      "0    20    75    90    30    50    10  ft_transformer\n",
      "1    75    90    50    30    20    10              lr\n",
      "2    75    90    50    30    20    10             rfc\n",
      "3    75    50    30    90    20    10            xgbc\n",
      "4    90    75    50    30    20    10            lgbm\n",
      "5    90    50    20    75    30    10             svm\n",
      "   per1  per2  per3  per4  per5  per6          models\n",
      "0    50    75    30    20    90    10  ft_transformer\n",
      "1    50    75    90    30    20    10              lr\n",
      "2    90    75    50    30    20    10             rfc\n",
      "3    90    75    30    50    20    10            xgbc\n",
      "4    90    75    50    20    30    10            lgbm\n",
      "5    20    30    75    10    50    90             svm\n",
      "   per1  per2  per3  per4  per5  per6          models\n",
      "0    50    20    75    90    30    10  ft_transformer\n",
      "1    50    75    90    30    20    10              lr\n",
      "2    30    75    90    50    20    10             rfc\n",
      "3    50    90    20    30    75    10            xgbc\n",
      "4    75    50    30    90    20    10            lgbm\n",
      "5    50    75    90    20    30    10             svm\n",
      "   per1  per2  per3  per4  per5  per6          models\n",
      "0    30    20    75    50    90    10  ft_transformer\n",
      "1    90    50    75    30    20    10              lr\n",
      "2    90    50    75    30    20    10             rfc\n",
      "3    50    90    20    75    30    10            xgbc\n",
      "4    50    90    75    30    20    10            lgbm\n",
      "5    20    30    50    90    75    10             svm\n",
      "   per1  per2  per3  per4  per5  per6          models\n",
      "0    20    50    30    90    75    10  ft_transformer\n",
      "1    90    75    50    30    20    10              lr\n",
      "2    30    50    75    90    20    10             rfc\n",
      "3    50    75    90    30    20    10            xgbc\n",
      "4    90    75    50    30    20    10            lgbm\n",
      "5    75    90    50    30    20    10             svm\n",
      "   per1  per2  per3  per4  per5  per6          models\n",
      "0    50    20    90    75    30    10  ft_transformer\n",
      "1    50    75    90    30    20    10              lr\n",
      "2    50    90    75    30    20    10             rfc\n",
      "3    75    90    50    20    30    10            xgbc\n",
      "4    90    75    50    30    20    10            lgbm\n",
      "5    20    75    30    90    50    10             svm\n",
      "   per1  per2  per3  per4  per5  per6          models\n",
      "0    75    30    90    20    50    10  ft_transformer\n",
      "1    50    75    90    30    20    10              lr\n",
      "2    90    75    50    30    20    10             rfc\n",
      "3    90    50    75    20    30    10            xgbc\n",
      "4    90    50    75    30    20    10            lgbm\n",
      "5    90    75    50    30    20    10             svm\n",
      "   per1  per2  per3  per4  per5  per6          models\n",
      "0    90    20    30    75    50    10  ft_transformer\n",
      "1    75    90    50    30    20    10              lr\n",
      "2    50    30    90    75    20    10             rfc\n",
      "3    50    30    20    75    90    10            xgbc\n",
      "4    75    30    90    50    20    10            lgbm\n",
      "5    20    75    50    90    30    10             svm\n"
     ]
    }
   ],
   "source": [
    "def mean_percentiles(length, df=shopper_df): \n",
    "    percentiles_list = [10, 20, 30, 50, 75, 90]\n",
    "    models_list = ['ft_transformer', 'lr', 'rfc', 'xgbc', 'lgbm', 'svm']\n",
    "    all_df = list()\n",
    "    for i in models_list:\n",
    "        means = list()\n",
    "        for j in percentiles_list:\n",
    "            model = df[(df.percentiles == j) & (df.models == i) & (df.length_text == length)]\n",
    "            mean_val = list(model[shopper_df_float].mean())\n",
    "            means.append(mean_val)\n",
    "        means_df = pd.DataFrame(means, columns=shopper_df_float).reset_index()\n",
    "        means_df['percentiles_name'] = pd.Series([10, 20, 30, 50, 75, 90])\n",
    "        means_df['models_name'] = pd.Series([model] * 6)\n",
    "        all_df.append(means_df)\n",
    "        \n",
    "    ranks_percentile_per_model = list()\n",
    "    for i in all_df:\n",
    "        i.drop(['index', 'models_name', 'percentiles_name'], axis=1, inplace=True)\n",
    "        ranks_percentile_per_model.append(mcdm.rank(i.to_numpy(), s_method='TOPSIS', alt_names=percentiles_list, is_benefit_x=[True]*len(shopper_df_float)))\n",
    "        \n",
    "    best_percentiles = list()\n",
    "    for val in ranks_percentile_per_model:\n",
    "        best_percentile_per_model = list()\n",
    "        # print(val)\n",
    "        for i in val:\n",
    "            best_percentile_per_model.append(i[0])\n",
    "        best_percentiles.append(best_percentile_per_model)\n",
    "        \n",
    "    models_df = pd.DataFrame(best_percentiles, columns=['per1', 'per2', 'per3', 'per4', 'per5', 'per6'])\n",
    "    models_df['models'] = pd.Series(['ft_transformer', 'lr', 'rfc', 'xgbc', 'lgbm', 'svm'])\n",
    "    return models_df\n",
    "\n",
    "best_percentiles_8 = mean_percentiles(8)\n",
    "best_percentiles_9 = mean_percentiles(9)\n",
    "best_percentiles_10 = mean_percentiles(10)\n",
    "best_percentiles_11 = mean_percentiles(11)\n",
    "best_percentiles_12 = mean_percentiles(12)\n",
    "best_percentiles_13 = mean_percentiles(13)\n",
    "best_percentiles_14 = mean_percentiles(14)\n",
    "best_percentiles_15 = mean_percentiles(15)\n",
    "best_percentiles_16 = mean_percentiles(16)\n",
    "best_percentiles_17 = mean_percentiles(17)\n",
    "\n",
    "print(best_percentiles_8)\n",
    "print(best_percentiles_9)\n",
    "print(best_percentiles_10)\n",
    "print(best_percentiles_11)\n",
    "print(best_percentiles_12)\n",
    "print(best_percentiles_13)\n",
    "print(best_percentiles_14)\n",
    "print(best_percentiles_15)\n",
    "print(best_percentiles_16)\n",
    "print(best_percentiles_17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mi_accuracy  mi_f1_score    mi_auc  mrmr_accuracy  mrmr_f1_score  mrmr_auc  \\\n",
      "0     0.706470     0.644810  0.752120       0.700700       0.647460  0.748670   \n",
      "1     0.705441     0.657071  0.705441       0.706171       0.651929  0.706171   \n",
      "2     0.707896     0.654670  0.707896       0.709721       0.652345  0.709721   \n",
      "3     0.711546     0.655753  0.711546       0.711745       0.652491  0.711745   \n",
      "4     0.711646     0.655358  0.711646       0.711878       0.652182  0.711878   \n",
      "5     0.713603     0.656924  0.713603       0.712276       0.652560  0.712276   \n",
      "0     0.710310     0.653510  0.753850       0.710020       0.648090  0.749740   \n",
      "1     0.709754     0.660716  0.709754       0.709522       0.655777  0.709522   \n",
      "2     0.712243     0.652631  0.712243       0.712177       0.653026  0.712177   \n",
      "3     0.713404     0.656905  0.713404       0.712674       0.656461  0.712674   \n",
      "4     0.713603     0.659719  0.713603       0.712807       0.657417  0.712807   \n",
      "5     0.714831     0.657855  0.714831       0.715328       0.658516  0.715328   \n",
      "0     0.711330     0.654030  0.757720       0.708650       0.651920  0.752430   \n",
      "1     0.711314     0.661814  0.711314       0.711745       0.658335  0.711745   \n",
      "2     0.712342     0.655950  0.712342       0.711944       0.652192  0.711944   \n",
      "3     0.712143     0.655481  0.712143       0.713470       0.656744  0.713470   \n",
      "4     0.712940     0.658492  0.712940       0.713570       0.658461  0.713570   \n",
      "5     0.713902     0.656467  0.713902       0.715096       0.658495  0.715096   \n",
      "0     0.707630     0.659220  0.754850       0.709900       0.656030  0.754640   \n",
      "1     0.712674     0.663928  0.712674       0.711447       0.662476  0.711447   \n",
      "2     0.711679     0.655995  0.711679       0.711745       0.653230  0.711745   \n",
      "3     0.712011     0.658628  0.712011       0.711612       0.659518  0.711612   \n",
      "4     0.714698     0.661370  0.714698       0.713039       0.658632  0.713039   \n",
      "5     0.713603     0.659624  0.713603       0.714167       0.658189  0.714167   \n",
      "0     0.707190     0.651570  0.756720       0.708100       0.654490  0.752160   \n",
      "1     0.712906     0.664366  0.712906       0.711248       0.663229  0.711248   \n",
      "2     0.712177     0.655723  0.712177       0.711878       0.655253  0.711878   \n",
      "3     0.712442     0.654437  0.712442       0.712575       0.655802  0.712575   \n",
      "4     0.713006     0.657550  0.713006       0.713006       0.658070  0.713006   \n",
      "5     0.713371     0.655349  0.713371       0.712608       0.655126  0.712608   \n",
      "0     0.708330     0.648710  0.751490       0.707900       0.653600  0.748930   \n",
      "1     0.711480     0.663271  0.711480       0.712342       0.663818  0.712342   \n",
      "2     0.712309     0.656136  0.712309       0.712077       0.655731  0.712077   \n",
      "3     0.712973     0.656670  0.712973       0.712309       0.654547  0.712309   \n",
      "4     0.713603     0.657999  0.713603       0.713172       0.657613  0.713172   \n",
      "5     0.713470     0.659321  0.713470       0.712807       0.656713  0.712807   \n",
      "\n",
      "   mi_mrmr_accuracy  mi_mrmr_f1_score  mi_mrmr_auc  pca_accuracy  \\\n",
      "0          0.691500          0.632940     0.742880      0.697720   \n",
      "1          0.699502          0.655175     0.699502      0.704181   \n",
      "2          0.706005          0.657588     0.706005      0.702080   \n",
      "3          0.708261          0.654748     0.708261      0.702190   \n",
      "4          0.708527          0.656610     0.708527      0.702323   \n",
      "5          0.708328          0.652013     0.708328      0.708473   \n",
      "0          0.708580          0.648130     0.750910      0.705030   \n",
      "1          0.706238          0.654263     0.706238      0.709845   \n",
      "2          0.711281          0.653288     0.711281      0.705642   \n",
      "3          0.711977          0.654669     0.711977      0.704093   \n",
      "4          0.712342          0.655982     0.712342      0.706239   \n",
      "5          0.714964          0.657674     0.714964      0.714314   \n",
      "0          0.706900          0.655980     0.754200      0.704890   \n",
      "1          0.708394          0.653956     0.708394      0.710752   \n",
      "2          0.711712          0.652174     0.711712      0.705531   \n",
      "3          0.712342          0.657151     0.712342      0.706305   \n",
      "4          0.713470          0.658566     0.713470      0.706084   \n",
      "5          0.715295          0.658627     0.715295      0.714226   \n",
      "0          0.707720          0.647200     0.751270      0.700610   \n",
      "1          0.711845          0.662237     0.711845      0.712920   \n",
      "2          0.712674          0.656116     0.712674      0.709646   \n",
      "3          0.712608          0.659164     0.712608      0.706217   \n",
      "4          0.713404          0.660780     0.713404      0.707854   \n",
      "5          0.714764          0.661177     0.714764      0.713982   \n",
      "0          0.706430          0.650010     0.753970      0.701860   \n",
      "1          0.711546          0.662740     0.711546      0.712655   \n",
      "2          0.713106          0.655867     0.713106      0.709381   \n",
      "3          0.712707          0.656474     0.712707      0.705088   \n",
      "4          0.713039          0.658784     0.713039      0.708319   \n",
      "5          0.713039          0.654520     0.713039      0.714049   \n",
      "0          0.710190          0.657270     0.754810      0.703040   \n",
      "1          0.711911          0.663288     0.711911      0.712655   \n",
      "2          0.710949          0.653877     0.710949      0.709535   \n",
      "3          0.711977          0.655781     0.711977      0.704757   \n",
      "4          0.713139          0.658165     0.713139      0.708584   \n",
      "5          0.713305          0.658780     0.713305      0.714049   \n",
      "\n",
      "   pca_f1_score   pca_auc  \n",
      "0      0.641120  0.748270  \n",
      "1      0.666463  0.704181  \n",
      "2      0.669096  0.702080  \n",
      "3      0.668183  0.702190  \n",
      "4      0.667076  0.702323  \n",
      "5      0.666828  0.708473  \n",
      "0      0.654610  0.751460  \n",
      "1      0.672274  0.709845  \n",
      "2      0.672785  0.705642  \n",
      "3      0.670399  0.704093  \n",
      "4      0.670528  0.706239  \n",
      "5      0.661418  0.714314  \n",
      "0      0.649910  0.751500  \n",
      "1      0.666807  0.710752  \n",
      "2      0.666905  0.705531  \n",
      "3      0.669596  0.706305  \n",
      "4      0.667586  0.706084  \n",
      "5      0.662225  0.714226  \n",
      "0      0.647850  0.749200  \n",
      "1      0.666285  0.712920  \n",
      "2      0.666674  0.709646  \n",
      "3      0.669418  0.706217  \n",
      "4      0.668711  0.707854  \n",
      "5      0.663982  0.713982  \n",
      "0      0.657540  0.750890  \n",
      "1      0.666338  0.712655  \n",
      "2      0.665821  0.709381  \n",
      "3      0.666748  0.705088  \n",
      "4      0.667587  0.708319  \n",
      "5      0.663936  0.714049  \n",
      "0      0.645680  0.750770  \n",
      "1      0.666303  0.712655  \n",
      "2      0.664995  0.709535  \n",
      "3      0.673456  0.704757  \n",
      "4      0.671088  0.708584  \n",
      "5      0.663936  0.714049  \n",
      "   mi_accuracy  mi_f1_score    mi_auc  mrmr_accuracy  mrmr_f1_score  mrmr_auc  \\\n",
      "0     0.715130     0.671370  0.764280       0.711080       0.672260  0.758320   \n",
      "1     0.714819     0.680078  0.714781       0.717513       0.679387  0.717472   \n",
      "2     0.720933     0.679932  0.720888       0.723592       0.679940  0.723545   \n",
      "3     0.720864     0.680227  0.720820       0.723351       0.681101  0.723305   \n",
      "4     0.721762     0.681145  0.721718       0.723627       0.681878  0.723582   \n",
      "5     0.722176     0.683090  0.722134       0.724905       0.681943  0.724858   \n",
      "0     0.721380     0.680020  0.765420       0.720650       0.674450  0.764970   \n",
      "1     0.721105     0.682295  0.721063       0.721174       0.681118  0.721131   \n",
      "2     0.724870     0.680131  0.724822       0.724732       0.680152  0.724684   \n",
      "3     0.724801     0.682797  0.724756       0.724560       0.681912  0.724513   \n",
      "4     0.724629     0.683913  0.724584       0.724214       0.682859  0.724169   \n",
      "5     0.725872     0.683417  0.725826       0.725838       0.683632  0.725792   \n",
      "0     0.723010     0.682820  0.761720       0.724580       0.681890  0.766720   \n",
      "1     0.722211     0.683127  0.722168       0.722280       0.681713  0.722236   \n",
      "2     0.724180     0.680663  0.724133       0.724214       0.680552  0.724167   \n",
      "3     0.723731     0.683063  0.723686       0.724214       0.681815  0.724168   \n",
      "4     0.723351     0.682873  0.723307       0.724491       0.682720  0.724445   \n",
      "5     0.725354     0.683058  0.725308       0.725907       0.685653  0.725863   \n",
      "0     0.722260     0.682820  0.763670       0.719760       0.673200  0.758820   \n",
      "1     0.723316     0.684114  0.723273       0.723109       0.682957  0.723065   \n",
      "2     0.723212     0.680687  0.723167       0.724629       0.682020  0.724582   \n",
      "3     0.724974     0.683663  0.724929       0.724352       0.682893  0.724307   \n",
      "4     0.724352     0.684550  0.724309       0.724767       0.684673  0.724723   \n",
      "5     0.725803     0.683969  0.725757       0.725630       0.684055  0.725585   \n",
      "0     0.719720     0.681550  0.764280       0.719850       0.679670  0.765500   \n",
      "1     0.723005     0.684089  0.722963       0.723523       0.685209  0.723481   \n",
      "2     0.724249     0.684233  0.724205       0.724249       0.681772  0.724203   \n",
      "3     0.723800     0.685500  0.723758       0.723972       0.685819  0.723931   \n",
      "4     0.723731     0.686535  0.723690       0.724940       0.686044  0.724897   \n",
      "5     0.725458     0.685696  0.725414       0.725112       0.683066  0.725067   \n",
      "0     0.721980     0.684170  0.762820       0.723620       0.677940  0.765750   \n",
      "1     0.723385     0.684367  0.723343       0.722591       0.683821  0.722548   \n",
      "2     0.724041     0.682340  0.723996       0.724111       0.682678  0.724066   \n",
      "3     0.723592     0.684502  0.723550       0.723212       0.684094  0.723170   \n",
      "4     0.724180     0.685350  0.724137       0.724801       0.685246  0.724758   \n",
      "5     0.724940     0.684462  0.724895       0.724698       0.683649  0.724653   \n",
      "\n",
      "   mi_mrmr_accuracy  mi_mrmr_f1_score  mi_mrmr_auc  pca_accuracy  \\\n",
      "0          0.706980          0.657760     0.759000      0.711410   \n",
      "1          0.708221          0.674500     0.708185      0.712690   \n",
      "2          0.716373          0.678016     0.716332      0.709443   \n",
      "3          0.717098          0.681163     0.717060      0.711446   \n",
      "4          0.717513          0.678667     0.717471      0.711792   \n",
      "5          0.717962          0.676308     0.717918      0.718724   \n",
      "0          0.723460          0.681070     0.764600      0.711610   \n",
      "1          0.720104          0.680813     0.720061      0.717227   \n",
      "2          0.724076          0.679806     0.724028      0.713082   \n",
      "3          0.723765          0.681588     0.723719      0.712391   \n",
      "4          0.724732          0.683196     0.724687      0.714302   \n",
      "5          0.725838          0.683733     0.725792      0.722432   \n",
      "0          0.722040          0.681490     0.766420      0.715860   \n",
      "1          0.720484          0.680075     0.720440      0.720267   \n",
      "2          0.724111          0.680830     0.724064      0.715431   \n",
      "3          0.724698          0.682393     0.724652      0.715523   \n",
      "4          0.724421          0.682589     0.724376      0.716951   \n",
      "5          0.725665          0.683469     0.725619      0.723422   \n",
      "0          0.721700          0.695500     0.765240      0.718130   \n",
      "1          0.723247          0.683538     0.723204      0.721833   \n",
      "2          0.723420          0.680158     0.723373      0.717204   \n",
      "3          0.724767          0.682335     0.724721      0.714786   \n",
      "4          0.724283          0.684621     0.724240      0.719162   \n",
      "5          0.725389          0.682911     0.725342      0.723054   \n",
      "0          0.722720          0.680070     0.765120      0.715700   \n",
      "1          0.723765          0.684979     0.723723      0.721027   \n",
      "2          0.723834          0.681920     0.723789      0.717319   \n",
      "3          0.725250          0.685113     0.725207      0.716628   \n",
      "4          0.724111          0.685840     0.724069      0.718494   \n",
      "5          0.725389          0.684213     0.725344      0.722731   \n",
      "0          0.722140          0.681010     0.765350      0.712620   \n",
      "1          0.723247          0.684582     0.723205      0.720843   \n",
      "2          0.724076          0.683206     0.724032      0.718079   \n",
      "3          0.724421          0.686590     0.724380      0.712621   \n",
      "4          0.724249          0.684950     0.724206      0.717596   \n",
      "5          0.725285          0.685015     0.725241      0.722685   \n",
      "\n",
      "   pca_f1_score   pca_auc  \n",
      "0      0.677320  0.758870  \n",
      "1      0.681670  0.712690  \n",
      "2      0.682708  0.709443  \n",
      "3      0.682265  0.711446  \n",
      "4      0.679162  0.711792  \n",
      "5      0.683624  0.718724  \n",
      "0      0.673970  0.755910  \n",
      "1      0.686201  0.717227  \n",
      "2      0.685359  0.713082  \n",
      "3      0.683637  0.712391  \n",
      "4      0.685203  0.714302  \n",
      "5      0.678594  0.722432  \n",
      "0      0.681160  0.761580  \n",
      "1      0.684261  0.720267  \n",
      "2      0.684619  0.715431  \n",
      "3      0.685577  0.715523  \n",
      "4      0.684725  0.716951  \n",
      "5      0.679006  0.723422  \n",
      "0      0.681300  0.759870  \n",
      "1      0.682042  0.721833  \n",
      "2      0.682943  0.717204  \n",
      "3      0.683860  0.714786  \n",
      "4      0.687018  0.719162  \n",
      "5      0.678746  0.723054  \n",
      "0      0.676300  0.760320  \n",
      "1      0.680958  0.721027  \n",
      "2      0.682229  0.717319  \n",
      "3      0.685461  0.716628  \n",
      "4      0.685520  0.718494  \n",
      "5      0.678663  0.722731  \n",
      "0      0.681010  0.757890  \n",
      "1      0.680865  0.720843  \n",
      "2      0.681999  0.718079  \n",
      "3      0.685025  0.712621  \n",
      "4      0.685119  0.717596  \n",
      "5      0.678522  0.722685  \n",
      "   mi_accuracy  mi_f1_score    mi_auc  mrmr_accuracy  mrmr_f1_score  mrmr_auc  \\\n",
      "0     0.717400     0.686140  0.762230       0.719520       0.683520  0.761270   \n",
      "1     0.720214     0.689872  0.720214       0.721214       0.690369  0.721214   \n",
      "2     0.726179     0.690609  0.726179       0.728250       0.691107  0.728250   \n",
      "3     0.728036     0.690798  0.728036       0.728464       0.690048  0.728464   \n",
      "4     0.727964     0.691156  0.727964       0.728750       0.691373  0.728750   \n",
      "5     0.728964     0.692412  0.728964       0.729143       0.691344  0.729143   \n",
      "0     0.726260     0.690080  0.766730       0.726330       0.694170  0.764230   \n",
      "1     0.723679     0.688312  0.723679       0.721714       0.685423  0.721714   \n",
      "2     0.729143     0.690635  0.729143       0.728679       0.689492  0.728679   \n",
      "3     0.728429     0.690958  0.728429       0.728679       0.690451  0.728679   \n",
      "4     0.728571     0.691596  0.728571       0.728214       0.691463  0.728214   \n",
      "5     0.730393     0.693431  0.730393       0.730643       0.693403  0.730643   \n",
      "0     0.726150     0.692720  0.767850       0.728020       0.690320  0.766590   \n",
      "1     0.725179     0.690501  0.725179       0.725893       0.690903  0.725893   \n",
      "2     0.728929     0.690594  0.728929       0.728571       0.689712  0.728571   \n",
      "3     0.728679     0.692270  0.728679       0.729071       0.691684  0.729071   \n",
      "4     0.729357     0.692683  0.729357       0.728143       0.691260  0.728143   \n",
      "5     0.730536     0.693414  0.730536       0.730536       0.693068  0.730536   \n",
      "0     0.727840     0.690720  0.766170       0.723250       0.681510  0.762750   \n",
      "1     0.727036     0.691432  0.727036       0.726714       0.691307  0.726714   \n",
      "2     0.729321     0.691472  0.729321       0.729429       0.691575  0.729429   \n",
      "3     0.728500     0.692038  0.728500       0.728357       0.691657  0.728357   \n",
      "4     0.728464     0.692231  0.728464       0.728429       0.692941  0.728429   \n",
      "5     0.730929     0.694925  0.730929       0.730107       0.694897  0.730107   \n",
      "0     0.727690     0.694610  0.766330       0.727190       0.690720  0.762630   \n",
      "1     0.727357     0.692089  0.727357       0.727357       0.691890  0.727357   \n",
      "2     0.729286     0.692817  0.729286       0.729179       0.692459  0.729179   \n",
      "3     0.728750     0.692572  0.728750       0.728036       0.690756  0.728036   \n",
      "4     0.729750     0.693897  0.729750       0.728214       0.691447  0.728214   \n",
      "5     0.730000     0.694324  0.730000       0.729750       0.693941  0.729750   \n",
      "0     0.724960     0.691770  0.765190       0.721750       0.696060  0.765570   \n",
      "1     0.727143     0.691991  0.727143       0.726286       0.691521  0.726286   \n",
      "2     0.729393     0.692627  0.729393       0.729679       0.692206  0.729679   \n",
      "3     0.728429     0.692916  0.728429       0.728393       0.691414  0.728393   \n",
      "4     0.729143     0.693413  0.729143       0.728393       0.691997  0.728393   \n",
      "5     0.730500     0.696405  0.730500       0.730071       0.695010  0.730071   \n",
      "\n",
      "   mi_mrmr_accuracy  mi_mrmr_f1_score  mi_mrmr_auc  pca_accuracy  \\\n",
      "0          0.712540          0.671590     0.759010      0.715560   \n",
      "1          0.718536          0.689465     0.718536      0.724833   \n",
      "2          0.724286          0.689108     0.724286      0.723762   \n",
      "3          0.725500          0.689495     0.725500      0.723357   \n",
      "4          0.725750          0.689339     0.725750      0.725952   \n",
      "5          0.727036          0.690800     0.727036      0.734119   \n",
      "0          0.725610          0.692920     0.764880      0.718630   \n",
      "1          0.722393          0.688373     0.722393      0.730167   \n",
      "2          0.728429          0.689496     0.728429      0.728905   \n",
      "3          0.729036          0.691562     0.729036      0.725762   \n",
      "4          0.727571          0.690820     0.727571      0.728000   \n",
      "5          0.730429          0.693008     0.730429      0.737595   \n",
      "0          0.727110          0.689690     0.765570      0.714960   \n",
      "1          0.724607          0.689793     0.724607      0.732810   \n",
      "2          0.728679          0.690146     0.728679      0.730976   \n",
      "3          0.728857          0.690594     0.728857      0.726357   \n",
      "4          0.728429          0.691158     0.728429      0.728905   \n",
      "5          0.730607          0.692998     0.730607      0.737810   \n",
      "0          0.726010          0.688170     0.765400      0.719450   \n",
      "1          0.726357          0.690679     0.726357      0.735929   \n",
      "2          0.728464          0.690146     0.728464      0.732381   \n",
      "3          0.727643          0.690166     0.727643      0.728095   \n",
      "4          0.728250          0.690910     0.728250      0.731738   \n",
      "5          0.730357          0.694552     0.730357      0.738214   \n",
      "0          0.725420          0.695320     0.767420      0.718890   \n",
      "1          0.727714          0.691840     0.727714      0.736048   \n",
      "2          0.729179          0.691466     0.729179      0.733619   \n",
      "3          0.728357          0.692226     0.728357      0.727833   \n",
      "4          0.727607          0.690766     0.727607      0.732262   \n",
      "5          0.729857          0.692838     0.729857      0.738167   \n",
      "0          0.726910          0.690410     0.766150      0.717240   \n",
      "1          0.726821          0.692018     0.726821      0.735881   \n",
      "2          0.729250          0.692091     0.729250      0.733167   \n",
      "3          0.729143          0.692124     0.729143      0.726048   \n",
      "4          0.728893          0.693013     0.728893      0.733690   \n",
      "5          0.730036          0.694147     0.730036      0.738214   \n",
      "\n",
      "   pca_f1_score   pca_auc  \n",
      "0      0.681190  0.759210  \n",
      "1      0.700857  0.724833  \n",
      "2      0.705866  0.723762  \n",
      "3      0.703598  0.723357  \n",
      "4      0.703389  0.725952  \n",
      "5      0.709558  0.734119  \n",
      "0      0.691720  0.759420  \n",
      "1      0.706550  0.730167  \n",
      "2      0.710381  0.728905  \n",
      "3      0.705006  0.725762  \n",
      "4      0.706686  0.728000  \n",
      "5      0.704686  0.737595  \n",
      "0      0.678240  0.758040  \n",
      "1      0.706009  0.732810  \n",
      "2      0.709162  0.730976  \n",
      "3      0.704916  0.726357  \n",
      "4      0.705415  0.728905  \n",
      "5      0.703268  0.737810  \n",
      "0      0.687880  0.760440  \n",
      "1      0.706796  0.735929  \n",
      "2      0.709712  0.732381  \n",
      "3      0.705911  0.728095  \n",
      "4      0.708627  0.731738  \n",
      "5      0.703271  0.738214  \n",
      "0      0.684050  0.761190  \n",
      "1      0.706844  0.736048  \n",
      "2      0.708765  0.733619  \n",
      "3      0.705049  0.727833  \n",
      "4      0.708734  0.732262  \n",
      "5      0.703627  0.738167  \n",
      "0      0.683510  0.760190  \n",
      "1      0.706603  0.735881  \n",
      "2      0.706860  0.733167  \n",
      "3      0.703834  0.726048  \n",
      "4      0.709310  0.733690  \n",
      "5      0.703682  0.738214  \n",
      "   mi_accuracy  mi_f1_score    mi_auc  mrmr_accuracy  mrmr_f1_score  mrmr_auc  \\\n",
      "0     0.744430     0.720560  0.792470       0.745490       0.728180  0.793350   \n",
      "1     0.747540     0.729460  0.747515       0.748428       0.729851  0.748402   \n",
      "2     0.753274     0.736549  0.753251       0.752423       0.735540  0.752400   \n",
      "3     0.752682     0.734469  0.752657       0.754754       0.736056  0.754728   \n",
      "4     0.753533     0.734861  0.753507       0.755790       0.735693  0.755762   \n",
      "5     0.753422     0.737672  0.753400       0.756863       0.738391  0.756837   \n",
      "0     0.751760     0.733830  0.795710       0.749870       0.731160  0.795020   \n",
      "1     0.751239     0.729938  0.751210       0.748909       0.726326  0.748878   \n",
      "2     0.756160     0.734381  0.756130       0.755901       0.735632  0.755873   \n",
      "3     0.755642     0.736193  0.755615       0.756160       0.736038  0.756132   \n",
      "4     0.755642     0.736629  0.755615       0.756382       0.736244  0.756354   \n",
      "5     0.756234     0.738691  0.756209       0.756752       0.738015  0.756725   \n",
      "0     0.751170     0.731860  0.795220       0.751670       0.731530  0.796930   \n",
      "1     0.755161     0.735210  0.755133       0.751757       0.730255  0.751728   \n",
      "2     0.754532     0.735293  0.754505       0.755716       0.735621  0.755688   \n",
      "3     0.754828     0.736638  0.754803       0.755531       0.736972  0.755505   \n",
      "4     0.755494     0.738896  0.755470       0.755198       0.735913  0.755171   \n",
      "5     0.755198     0.738620  0.755175       0.755420       0.737872  0.755395   \n",
      "0     0.750940     0.732810  0.798250       0.751420       0.737360  0.796680   \n",
      "1     0.755013     0.735626  0.754986       0.756715       0.737085  0.756687   \n",
      "2     0.756271     0.736815  0.756244       0.755568       0.735212  0.755540   \n",
      "3     0.754791     0.737299  0.754766       0.754717       0.735319  0.754690   \n",
      "4     0.754828     0.736561  0.754802       0.755420       0.736331  0.755393   \n",
      "5     0.755457     0.738774  0.755433       0.754828       0.736307  0.754802   \n",
      "0     0.752640     0.735020  0.795540       0.750350       0.731740  0.793410   \n",
      "1     0.755531     0.736628  0.755504       0.755568       0.736561  0.755541   \n",
      "2     0.755346     0.736681  0.755320       0.755494       0.736050  0.755467   \n",
      "3     0.754347     0.735822  0.754321       0.754791       0.736233  0.754765   \n",
      "4     0.755494     0.738150  0.755470       0.755531       0.736804  0.755505   \n",
      "5     0.754754     0.739129  0.754732       0.755198       0.737659  0.755173   \n",
      "0     0.749860     0.730820  0.796090       0.750340       0.731070  0.795170   \n",
      "1     0.754606     0.735978  0.754580       0.753866       0.735839  0.753841   \n",
      "2     0.755827     0.737350  0.755801       0.755901       0.736400  0.755874   \n",
      "3     0.755346     0.735411  0.755318       0.755161       0.736118  0.755134   \n",
      "4     0.755901     0.737692  0.755875       0.755827       0.737870  0.755802   \n",
      "5     0.755013     0.738158  0.754989       0.754643       0.738135  0.754620   \n",
      "\n",
      "   mi_mrmr_accuracy  mi_mrmr_f1_score  mi_mrmr_auc  pca_accuracy  \\\n",
      "0          0.732890          0.712110     0.789920      0.731810   \n",
      "1          0.744062          0.726557     0.744039      0.737830   \n",
      "2          0.751091          0.737098     0.751072      0.737928   \n",
      "3          0.752497          0.736027     0.752474      0.736104   \n",
      "4          0.751683          0.734201     0.751659      0.738150   \n",
      "5          0.752238          0.737019     0.752217      0.747867   \n",
      "0          0.750800          0.732430     0.793290      0.737770   \n",
      "1          0.749205          0.727852     0.749176      0.743379   \n",
      "2          0.755975          0.734342     0.755945      0.740518   \n",
      "3          0.756049          0.736620     0.756022      0.736276   \n",
      "4          0.756049          0.735801     0.756021      0.740691   \n",
      "5          0.756863          0.738211     0.756836      0.749199   \n",
      "0          0.752410          0.734970     0.796090      0.742210   \n",
      "1          0.751646          0.730219     0.751617      0.743527   \n",
      "2          0.755716          0.735577     0.755688      0.742244   \n",
      "3          0.755864          0.736484     0.755837      0.738323   \n",
      "4          0.756715          0.737229     0.756687      0.740025   \n",
      "5          0.756493          0.737094     0.756466      0.749199   \n",
      "0          0.752710          0.734120     0.797730      0.742390   \n",
      "1          0.755679          0.736191     0.755652      0.745623   \n",
      "2          0.755198          0.735774     0.755171      0.744562   \n",
      "3          0.754125          0.736074     0.754100      0.739729   \n",
      "4          0.754939          0.736766     0.754913      0.742589   \n",
      "5          0.755494          0.738162     0.755469      0.748829   \n",
      "0          0.752490          0.735700     0.796730      0.741610   \n",
      "1          0.755679          0.736187     0.755652      0.745869   \n",
      "2          0.755716          0.735473     0.755688      0.745351   \n",
      "3          0.755013          0.737039     0.754988      0.740395   \n",
      "4          0.755753          0.736704     0.755726      0.743674   \n",
      "5          0.755864          0.739135     0.755840      0.748681   \n",
      "0          0.747950          0.732260     0.795260      0.741130   \n",
      "1          0.755013          0.736274     0.754987      0.745795   \n",
      "2          0.756160          0.737366     0.756133      0.745203   \n",
      "3          0.756160          0.736716     0.756133      0.738866   \n",
      "4          0.755050          0.737148     0.755025      0.744735   \n",
      "5          0.754680          0.738269     0.754657      0.748557   \n",
      "\n",
      "   pca_f1_score   pca_auc  \n",
      "0      0.724580  0.784850  \n",
      "1      0.719459  0.737814  \n",
      "2      0.727583  0.737919  \n",
      "3      0.723096  0.736092  \n",
      "4      0.724590  0.738138  \n",
      "5      0.730908  0.747851  \n",
      "0      0.721940  0.788240  \n",
      "1      0.725565  0.743363  \n",
      "2      0.729499  0.740508  \n",
      "3      0.723726  0.736265  \n",
      "4      0.727631  0.740679  \n",
      "5      0.730448  0.749181  \n",
      "0      0.722560  0.789400  \n",
      "1      0.721891  0.743507  \n",
      "2      0.729424  0.742232  \n",
      "3      0.725057  0.738311  \n",
      "4      0.726520  0.740013  \n",
      "5      0.727864  0.749179  \n",
      "0      0.724160  0.789790  \n",
      "1      0.723446  0.745603  \n",
      "2      0.730460  0.744549  \n",
      "3      0.726250  0.739717  \n",
      "4      0.728772  0.742577  \n",
      "5      0.724701  0.748807  \n",
      "0      0.723090  0.788760  \n",
      "1      0.723673  0.745850  \n",
      "2      0.729425  0.745337  \n",
      "3      0.726373  0.740382  \n",
      "4      0.729157  0.743661  \n",
      "5      0.725694  0.748660  \n",
      "0      0.719810  0.790420  \n",
      "1      0.723526  0.745775  \n",
      "2      0.728560  0.745188  \n",
      "3      0.725840  0.738854  \n",
      "4      0.730895  0.744722  \n",
      "5      0.725773  0.748537  \n",
      "   mi_accuracy  mi_f1_score    mi_auc  mrmr_accuracy  mrmr_f1_score  mrmr_auc  \\\n",
      "0     0.732080     0.705330  0.782670       0.733100       0.713930  0.782910   \n",
      "1     0.723036     0.694311  0.723000       0.723342       0.694543  0.723306   \n",
      "2     0.739134     0.717105  0.739104       0.739134       0.716043  0.739103   \n",
      "3     0.739057     0.714465  0.739024       0.738635       0.713583  0.738602   \n",
      "4     0.739287     0.714639  0.739254       0.738712       0.713174  0.738678   \n",
      "5     0.739134     0.715347  0.739102       0.738559       0.715112  0.738527   \n",
      "0     0.740170     0.716070  0.784880       0.738820       0.713800  0.785300   \n",
      "1     0.727482     0.697109  0.727443       0.723419       0.690503  0.723378   \n",
      "2     0.739862     0.714969  0.739829       0.739785       0.714885  0.739752   \n",
      "3     0.739747     0.714807  0.739714       0.740169       0.715470  0.740135   \n",
      "4     0.739977     0.715012  0.739944       0.740015       0.715066  0.739982   \n",
      "5     0.739555     0.714657  0.739522       0.739977       0.715011  0.739944   \n",
      "0     0.738090     0.713570  0.786370       0.737020       0.710200  0.785890   \n",
      "1     0.730318     0.699417  0.730279       0.728938       0.697014  0.728898   \n",
      "2     0.739747     0.714735  0.739714       0.739939       0.714957  0.739905   \n",
      "3     0.739939     0.714958  0.739905       0.739785       0.715173  0.739752   \n",
      "4     0.740245     0.715739  0.740212       0.740514       0.716393  0.740481   \n",
      "5     0.740092     0.715618  0.740059       0.739747       0.715017  0.739714   \n",
      "0     0.739640     0.718510  0.785030       0.738480       0.714980  0.787430   \n",
      "1     0.732541     0.703407  0.732504       0.733039       0.703964  0.733002   \n",
      "2     0.739747     0.714902  0.739714       0.739900       0.714927  0.739867   \n",
      "3     0.739977     0.715012  0.739944       0.740437       0.715959  0.740404   \n",
      "4     0.740590     0.716480  0.740558       0.740514       0.716751  0.740482   \n",
      "5     0.740245     0.716239  0.740213       0.740284       0.716739  0.740252   \n",
      "0     0.739640     0.716010  0.789500       0.735840       0.709260  0.784970   \n",
      "1     0.732580     0.703510  0.732542       0.730855       0.702045  0.730818   \n",
      "2     0.739900     0.715754  0.739868       0.740399       0.715881  0.740366   \n",
      "3     0.739900     0.715070  0.739867       0.740130       0.715840  0.740098   \n",
      "4     0.740360     0.717331  0.740329       0.740207       0.716306  0.740175   \n",
      "5     0.739632     0.715946  0.739600       0.739785       0.715997  0.739753   \n",
      "0     0.738060     0.712220  0.786490       0.736540       0.710030  0.785340   \n",
      "1     0.732810     0.704054  0.732772       0.730548       0.701105  0.730510   \n",
      "2     0.740054     0.715590  0.740021       0.739900       0.715640  0.739868   \n",
      "3     0.739939     0.714958  0.739905       0.739939       0.714958  0.739905   \n",
      "4     0.739555     0.716172  0.739524       0.740590       0.716885  0.740558   \n",
      "5     0.739709     0.715917  0.739677       0.739670       0.715980  0.739639   \n",
      "\n",
      "   mi_mrmr_accuracy  mi_mrmr_f1_score  mi_mrmr_auc  pca_accuracy  \\\n",
      "0          0.730620          0.711300     0.782080      0.719200   \n",
      "1          0.721388          0.693880     0.721353      0.733189   \n",
      "2          0.736182          0.717318     0.736157      0.735718   \n",
      "3          0.735914          0.712757     0.735883      0.736893   \n",
      "4          0.736336          0.712891     0.736305      0.739882   \n",
      "5          0.736259          0.715640     0.736231      0.743689   \n",
      "0          0.739360          0.715980     0.787650      0.727200   \n",
      "1          0.723879          0.692218     0.723840      0.735590   \n",
      "2          0.739325          0.715355     0.739293      0.738809   \n",
      "3          0.739824          0.714962     0.739790      0.738886   \n",
      "4          0.739977          0.715012     0.739944      0.741569   \n",
      "5          0.739977          0.715035     0.739944      0.744916   \n",
      "0          0.738620          0.715740     0.786050      0.723330   \n",
      "1          0.725374          0.692825     0.725333      0.737200   \n",
      "2          0.739785          0.714956     0.739752      0.740981   \n",
      "3          0.739900          0.714903     0.739867      0.737941   \n",
      "4          0.739977          0.715012     0.739944      0.743076   \n",
      "5          0.739670          0.714555     0.739637      0.745171   \n",
      "0          0.737290          0.711260     0.787250      0.732220   \n",
      "1          0.733154          0.704316     0.733117      0.736893   \n",
      "2          0.739900          0.714904     0.739867      0.739525   \n",
      "3          0.740015          0.715066     0.739982      0.740445   \n",
      "4          0.740245          0.715806     0.740212      0.743562   \n",
      "5          0.739977          0.715436     0.739944      0.745324   \n",
      "0          0.738440          0.717960     0.786050      0.727100   \n",
      "1          0.733001          0.704666     0.732965      0.737609   \n",
      "2          0.740092          0.715742     0.740059      0.740445   \n",
      "3          0.739670          0.714916     0.739637      0.737583   \n",
      "4          0.740284          0.716508     0.740252      0.743945   \n",
      "5          0.739747          0.716325     0.739715      0.745299   \n",
      "0          0.736220          0.709440     0.783530      0.727830   \n",
      "1          0.732771          0.704267     0.732734      0.737685   \n",
      "2          0.739977          0.716559     0.739945      0.740393   \n",
      "3          0.739977          0.715813     0.739945      0.740240   \n",
      "4          0.740360          0.716511     0.740328      0.741901   \n",
      "5          0.739939          0.716447     0.739907      0.745069   \n",
      "\n",
      "   pca_f1_score   pca_auc  \n",
      "0      0.695600  0.772460  \n",
      "1      0.714993  0.733189  \n",
      "2      0.726830  0.735718  \n",
      "3      0.724643  0.736893  \n",
      "4      0.727914  0.739882  \n",
      "5      0.725403  0.743689  \n",
      "0      0.709840  0.776940  \n",
      "1      0.711045  0.735590  \n",
      "2      0.727183  0.738809  \n",
      "3      0.724780  0.738886  \n",
      "4      0.728119  0.741569  \n",
      "5      0.723795  0.744916  \n",
      "0      0.698390  0.770660  \n",
      "1      0.711950  0.737200  \n",
      "2      0.727745  0.740981  \n",
      "3      0.724476  0.737941  \n",
      "4      0.728879  0.743076  \n",
      "5      0.723134  0.745171  \n",
      "0      0.710600  0.779610  \n",
      "1      0.710218  0.736893  \n",
      "2      0.725317  0.739525  \n",
      "3      0.726059  0.740445  \n",
      "4      0.729456  0.743562  \n",
      "5      0.724137  0.745324  \n",
      "0      0.703790  0.774660  \n",
      "1      0.711139  0.737609  \n",
      "2      0.724578  0.740445  \n",
      "3      0.723258  0.737583  \n",
      "4      0.730132  0.743945  \n",
      "5      0.723826  0.745299  \n",
      "0      0.706890  0.777450  \n",
      "1      0.711215  0.737685  \n",
      "2      0.724302  0.740393  \n",
      "3      0.726186  0.740240  \n",
      "4      0.727685  0.741901  \n",
      "5      0.723506  0.745069  \n",
      "   mi_accuracy  mi_f1_score    mi_auc  mrmr_accuracy  mrmr_f1_score  mrmr_auc  \\\n",
      "0     0.743450     0.730520  0.786860       0.750140       0.736910  0.794260   \n",
      "1     0.739960     0.719553  0.739931       0.743340       0.720968  0.743308   \n",
      "2     0.753678     0.744125  0.753663       0.758489       0.749145  0.758474   \n",
      "3     0.753837     0.744459  0.753823       0.760437       0.747689  0.760417   \n",
      "4     0.754314     0.744490  0.754299       0.759523       0.748256  0.759505   \n",
      "5     0.753121     0.746097  0.753110       0.759722       0.749004  0.759705   \n",
      "0     0.755020     0.742160  0.793970       0.757000       0.745540  0.793550   \n",
      "1     0.746879     0.724033  0.746846       0.746441       0.722720  0.746407   \n",
      "2     0.761193     0.748118  0.761172       0.761034       0.747917  0.761013   \n",
      "3     0.760994     0.749681  0.760976       0.760199       0.749347  0.760182   \n",
      "4     0.760835     0.749339  0.760817       0.760477       0.749722  0.760460   \n",
      "5     0.760557     0.750834  0.760541       0.760517       0.750391  0.760501   \n",
      "0     0.755230     0.743470  0.793600       0.755440       0.741420  0.794880   \n",
      "1     0.750577     0.728146  0.750544       0.749861       0.726155  0.749827   \n",
      "2     0.760437     0.748428  0.760419       0.760755       0.747696  0.760735   \n",
      "3     0.760199     0.748148  0.760180       0.760437       0.748684  0.760419   \n",
      "4     0.759602     0.748558  0.759585       0.760278       0.749249  0.760261   \n",
      "5     0.760477     0.750169  0.760461       0.760954       0.750341  0.760937   \n",
      "0     0.757010     0.745760  0.795640       0.755680       0.742990  0.795320   \n",
      "1     0.751292     0.729839  0.751261       0.751133       0.729708  0.751102   \n",
      "2     0.761431     0.749157  0.761412       0.760755       0.749291  0.760737   \n",
      "3     0.760676     0.749754  0.760659       0.760477       0.749252  0.760459   \n",
      "4     0.760557     0.749793  0.760540       0.760755       0.748956  0.760737   \n",
      "5     0.760915     0.751462  0.760900       0.760915       0.750839  0.760899   \n",
      "0     0.758400     0.745460  0.796180       0.753030       0.739680  0.794590   \n",
      "1     0.750258     0.730056  0.750229       0.751332       0.731190  0.751302   \n",
      "2     0.760477     0.749888  0.760460       0.760517       0.748816  0.760499   \n",
      "3     0.759722     0.749897  0.759706       0.759602       0.748882  0.759586   \n",
      "4     0.759125     0.749227  0.759110       0.760477       0.749819  0.760460   \n",
      "5     0.759761     0.750931  0.759747       0.759841       0.750421  0.759826   \n",
      "0     0.749320     0.738130  0.794960       0.756110       0.743200  0.794730   \n",
      "1     0.750895     0.730683  0.750865       0.751213       0.730716  0.751183   \n",
      "2     0.760557     0.750295  0.760540       0.759761       0.748630  0.759744   \n",
      "3     0.759523     0.749760  0.759507       0.759841       0.749637  0.759825   \n",
      "4     0.759324     0.749272  0.759308       0.761193       0.750882  0.761176   \n",
      "5     0.760398     0.751634  0.760384       0.758966       0.750349  0.758953   \n",
      "\n",
      "   mi_mrmr_accuracy  mi_mrmr_f1_score  mi_mrmr_auc  pca_accuracy  \\\n",
      "0          0.741510          0.722780     0.789740      0.731850   \n",
      "1          0.736581          0.717490     0.736554      0.742751   \n",
      "2          0.749543          0.739740     0.749528      0.743228   \n",
      "3          0.749185          0.739617     0.749170      0.739412   \n",
      "4          0.749026          0.739823     0.749012      0.741320   \n",
      "5          0.748827          0.744249     0.748820      0.756030   \n",
      "0          0.758930          0.747620     0.797550      0.741230   \n",
      "1          0.746123          0.722572     0.746090      0.746568   \n",
      "2          0.760795          0.748370     0.760776      0.744341   \n",
      "3          0.760239          0.749358     0.760221      0.743493   \n",
      "4          0.760557          0.749968     0.760540      0.745163   \n",
      "5          0.760398          0.750582     0.760382      0.756692   \n",
      "0          0.757900          0.747090     0.795360      0.744440   \n",
      "1          0.747753          0.724609     0.747720      0.746912   \n",
      "2          0.760398          0.748243     0.760379      0.747548   \n",
      "3          0.760755          0.748658     0.760736      0.742248   \n",
      "4          0.760915          0.749204     0.760896      0.746144   \n",
      "5          0.760398          0.750164     0.760381      0.756321   \n",
      "0          0.757930          0.744680     0.795180      0.738210   \n",
      "1          0.752207          0.730055     0.752174      0.748370   \n",
      "2          0.760994          0.748257     0.760974      0.748264   \n",
      "3          0.759960          0.748856     0.759943      0.745163   \n",
      "4          0.760636          0.749608     0.760619      0.750146   \n",
      "5          0.760596          0.749614     0.760579      0.756374   \n",
      "0          0.756580          0.747030     0.797310      0.741640   \n",
      "1          0.751412          0.731110     0.751382      0.748290   \n",
      "2          0.760437          0.748102     0.760418      0.748900   \n",
      "3          0.759364          0.748637     0.759347      0.743493   \n",
      "4          0.760119          0.749285     0.760102      0.749775   \n",
      "5          0.760437          0.751056     0.760422      0.756745   \n",
      "0          0.755380          0.740850     0.793310      0.742110   \n",
      "1          0.751451          0.730790     0.751421      0.748184   \n",
      "2          0.760596          0.749939     0.760580      0.749828   \n",
      "3          0.759841          0.750387     0.759826      0.744368   \n",
      "4          0.759801          0.749928     0.759786      0.749934   \n",
      "5          0.760318          0.751292     0.760304      0.756613   \n",
      "\n",
      "   pca_f1_score   pca_auc  \n",
      "0      0.731360  0.781090  \n",
      "1      0.727470  0.742736  \n",
      "2      0.739112  0.743224  \n",
      "3      0.731781  0.739404  \n",
      "4      0.734694  0.741313  \n",
      "5      0.747589  0.756021  \n",
      "0      0.728510  0.786070  \n",
      "1      0.725011  0.746547  \n",
      "2      0.736988  0.744334  \n",
      "3      0.733610  0.743483  \n",
      "4      0.736594  0.745154  \n",
      "5      0.746236  0.756681  \n",
      "0      0.731110  0.788020  \n",
      "1      0.725864  0.746892  \n",
      "2      0.739795  0.747541  \n",
      "3      0.732232  0.742238  \n",
      "4      0.737142  0.746135  \n",
      "5      0.745403  0.756310  \n",
      "0      0.723560  0.785480  \n",
      "1      0.727075  0.748349  \n",
      "2      0.739894  0.748256  \n",
      "3      0.735442  0.745153  \n",
      "4      0.741404  0.750137  \n",
      "5      0.744146  0.756362  \n",
      "0      0.729360  0.786160  \n",
      "1      0.726870  0.748270  \n",
      "2      0.738474  0.748890  \n",
      "3      0.732861  0.743483  \n",
      "4      0.741913  0.749767  \n",
      "5      0.743674  0.756732  \n",
      "0      0.724490  0.787760  \n",
      "1      0.726540  0.748164  \n",
      "2      0.738818  0.749817  \n",
      "3      0.734754  0.744358  \n",
      "4      0.741734  0.749925  \n",
      "5      0.744172  0.756600  \n",
      "   mi_accuracy  mi_f1_score    mi_auc  mrmr_accuracy  mrmr_f1_score  mrmr_auc  \\\n",
      "0     0.747980     0.732900  0.801340       0.740950       0.726900  0.798960   \n",
      "1     0.737866     0.717146  0.737836       0.739473       0.716302  0.739439   \n",
      "2     0.755295     0.747385  0.755282       0.761145       0.751339  0.761129   \n",
      "3     0.756077     0.746555  0.756062       0.760569       0.749026  0.760550   \n",
      "4     0.756654     0.747164  0.756639       0.760692       0.749120  0.760673   \n",
      "5     0.756613     0.751326  0.756604       0.761145       0.751809  0.761130   \n",
      "0     0.759910     0.748440  0.805520       0.760100       0.748740  0.803780   \n",
      "1     0.744046     0.719876  0.744011       0.743511       0.718225  0.743474   \n",
      "2     0.761640     0.749637  0.761620       0.761516       0.750236  0.761498   \n",
      "3     0.761640     0.750513  0.761622       0.761805       0.750868  0.761787   \n",
      "4     0.762011     0.751759  0.761994       0.762093       0.751882  0.762076   \n",
      "5     0.762217     0.752853  0.762201       0.762546       0.753347  0.762531   \n",
      "0     0.762500     0.755170  0.803900       0.761020       0.749970  0.806180   \n",
      "1     0.749197     0.726447  0.749162       0.747919       0.724424  0.747884   \n",
      "2     0.761393     0.749424  0.761373       0.761846       0.750349  0.761827   \n",
      "3     0.761805     0.751651  0.761788       0.761640       0.751181  0.761623   \n",
      "4     0.761640     0.750366  0.761621       0.762258       0.751982  0.762241   \n",
      "5     0.763123     0.754423  0.763109       0.762464       0.752935  0.762448   \n",
      "0     0.758430     0.751340  0.805430       0.757650       0.748830  0.803200   \n",
      "1     0.750721     0.730077  0.750690       0.751339       0.730170  0.751307   \n",
      "2     0.761557     0.750269  0.761539       0.761805       0.750208  0.761786   \n",
      "3     0.762011     0.751782  0.761994       0.761640       0.750868  0.761622   \n",
      "4     0.761846     0.751252  0.761829       0.761722       0.750650  0.761704   \n",
      "5     0.762835     0.753749  0.762820       0.763288       0.754129  0.763273   \n",
      "0     0.757720     0.747610  0.806800       0.759000       0.748930  0.805670   \n",
      "1     0.752246     0.732690  0.752216       0.751998       0.731964  0.751968   \n",
      "2     0.762134     0.751244  0.762116       0.761805       0.750248  0.761786   \n",
      "3     0.761763     0.751848  0.761747       0.761640       0.750383  0.761621   \n",
      "4     0.762258     0.751643  0.762240       0.761310       0.750614  0.761293   \n",
      "5     0.763164     0.754285  0.763150       0.763370       0.754423  0.763356   \n",
      "0     0.757530     0.746480  0.803120       0.758670       0.748610  0.799540   \n",
      "1     0.753440     0.733704  0.753410       0.752905       0.733168  0.752874   \n",
      "2     0.761599     0.750109  0.761580       0.761846       0.750499  0.761827   \n",
      "3     0.761846     0.751913  0.761830       0.762299       0.752457  0.762283   \n",
      "4     0.761887     0.750589  0.761869       0.762093       0.751629  0.762076   \n",
      "5     0.763247     0.754628  0.763233       0.762794       0.754066  0.762779   \n",
      "\n",
      "   mi_mrmr_accuracy  mi_mrmr_f1_score  mi_mrmr_auc  pca_accuracy  \\\n",
      "0          0.744760          0.735580     0.801140      0.744600   \n",
      "1          0.737124          0.717782     0.737096      0.749231   \n",
      "2          0.753770          0.746485     0.753758      0.750522   \n",
      "3          0.754759          0.745718     0.754744      0.747720   \n",
      "4          0.755377          0.747005     0.755364      0.752885   \n",
      "5          0.753935          0.748726     0.753927      0.761868   \n",
      "0          0.760110          0.750030     0.807350      0.742470   \n",
      "1          0.742027          0.716591     0.741990      0.751181   \n",
      "2          0.761599          0.749561     0.761579      0.749423   \n",
      "3          0.761516          0.750195     0.761498      0.747802   \n",
      "4          0.762217          0.751959     0.762200      0.751071   \n",
      "5          0.762588          0.753553     0.762573      0.762115   \n",
      "0          0.760190          0.749440     0.803270      0.743440   \n",
      "1          0.744211          0.719853     0.744175      0.752390   \n",
      "2          0.761640          0.749637     0.761620      0.755110   \n",
      "3          0.761393          0.750253     0.761374      0.747995   \n",
      "4          0.761805          0.751317     0.761787      0.753022   \n",
      "5          0.762258          0.752677     0.762242      0.762885   \n",
      "0          0.760490          0.751650     0.804530      0.743130   \n",
      "1          0.750803          0.729393     0.750771      0.752390   \n",
      "2          0.761310          0.749671     0.761291      0.753187   \n",
      "3          0.762052          0.751793     0.762035      0.750440   \n",
      "4          0.761475          0.750062     0.761456      0.754451   \n",
      "5          0.763041          0.753411     0.763025      0.762555   \n",
      "0          0.760670          0.750950     0.802720      0.744430   \n",
      "1          0.752410          0.732075     0.752379      0.752225   \n",
      "2          0.761516          0.750129     0.761498      0.752473   \n",
      "3          0.761351          0.750180     0.761333      0.751978   \n",
      "4          0.761516          0.751097     0.761499      0.754505   \n",
      "5          0.763865          0.755353     0.763851      0.762967   \n",
      "0          0.759020          0.747940     0.805870      0.747420   \n",
      "1          0.751792          0.731758     0.751762      0.752225   \n",
      "2          0.761887          0.750908     0.761869      0.751896   \n",
      "3          0.762340          0.752544     0.762324      0.749588   \n",
      "4          0.761763          0.750600     0.761745      0.754286   \n",
      "5          0.762835          0.754557     0.762821      0.762940   \n",
      "\n",
      "   pca_f1_score   pca_auc  \n",
      "0      0.737070  0.795340  \n",
      "1      0.735812  0.749231  \n",
      "2      0.749504  0.750522  \n",
      "3      0.744351  0.747720  \n",
      "4      0.749603  0.752885  \n",
      "5      0.754891  0.761868  \n",
      "0      0.741430  0.793530  \n",
      "1      0.732879  0.751181  \n",
      "2      0.745618  0.749423  \n",
      "3      0.741854  0.747802  \n",
      "4      0.746304  0.751071  \n",
      "5      0.752018  0.762115  \n",
      "0      0.728170  0.796510  \n",
      "1      0.734146  0.752390  \n",
      "2      0.750552  0.755110  \n",
      "3      0.741988  0.747995  \n",
      "4      0.748132  0.753022  \n",
      "5      0.753973  0.762885  \n",
      "0      0.732410  0.795020  \n",
      "1      0.733268  0.752390  \n",
      "2      0.748286  0.753187  \n",
      "3      0.744270  0.750440  \n",
      "4      0.750071  0.754451  \n",
      "5      0.753698  0.762555  \n",
      "0      0.731880  0.795860  \n",
      "1      0.733340  0.752225  \n",
      "2      0.745957  0.752473  \n",
      "3      0.745913  0.751978  \n",
      "4      0.748995  0.754505  \n",
      "5      0.754527  0.762967  \n",
      "0      0.739600  0.796160  \n",
      "1      0.733325  0.752225  \n",
      "2      0.744426  0.751896  \n",
      "3      0.743232  0.749588  \n",
      "4      0.749367  0.754286  \n",
      "5      0.754433  0.762940  \n",
      "   mi_accuracy  mi_f1_score    mi_auc  mrmr_accuracy  mrmr_f1_score  mrmr_auc  \\\n",
      "0     0.739240     0.725290  0.788360       0.740630       0.732060  0.793140   \n",
      "1     0.728102     0.707141  0.728072       0.734158       0.713315  0.734127   \n",
      "2     0.744606     0.739051  0.744597       0.745800       0.741067  0.745792   \n",
      "3     0.744350     0.738821  0.744341       0.747846       0.740797  0.747835   \n",
      "4     0.745373     0.739565  0.745364       0.747932       0.741094  0.747921   \n",
      "5     0.742857     0.743501  0.742858       0.749638       0.743374  0.749627   \n",
      "0     0.748660     0.742360  0.793420       0.746910       0.741570  0.793190   \n",
      "1     0.739360     0.716578  0.739326       0.741066       0.718752  0.741032   \n",
      "2     0.751514     0.742533  0.751499       0.751642       0.742629  0.751627   \n",
      "3     0.750746     0.743916  0.750735       0.750959       0.744022  0.750948   \n",
      "4     0.750448     0.744666  0.750438       0.749893       0.743785  0.749883   \n",
      "5     0.751002     0.745101  0.750992       0.751429       0.745540  0.751419   \n",
      "0     0.744220     0.735200  0.791630       0.747930       0.742190  0.793200   \n",
      "1     0.742814     0.721569  0.742782       0.742345       0.721287  0.742313   \n",
      "2     0.751045     0.743099  0.751032       0.749936       0.741782  0.749923   \n",
      "3     0.750832     0.744914  0.750822       0.750618       0.744434  0.750608   \n",
      "4     0.750192     0.744783  0.750183       0.750874       0.743931  0.750863   \n",
      "5     0.750832     0.745967  0.750823       0.751514       0.745200  0.751503   \n",
      "0     0.747460     0.746090  0.796890       0.746690       0.742000  0.792720   \n",
      "1     0.743667     0.723181  0.743636       0.744733       0.724766  0.744703   \n",
      "2     0.751343     0.743553  0.751330       0.751684       0.743510  0.751671   \n",
      "3     0.749638     0.744364  0.749629       0.751557       0.744199  0.751544   \n",
      "4     0.750832     0.744700  0.750821       0.751087       0.744879  0.751077   \n",
      "5     0.750704     0.746019  0.750696       0.751727       0.745715  0.751717   \n",
      "0     0.746090     0.742440  0.790050       0.748780       0.739650  0.790050   \n",
      "1     0.742687     0.722243  0.742655       0.743369       0.723493  0.743338   \n",
      "2     0.751599     0.743575  0.751586       0.751002       0.743509  0.750990   \n",
      "3     0.749851     0.744408  0.749842       0.750576       0.744966  0.750566   \n",
      "4     0.750277     0.744566  0.750268       0.750192       0.744354  0.750182   \n",
      "5     0.751599     0.745146  0.751588       0.751727       0.745688  0.751717   \n",
      "0     0.745930     0.742260  0.793340       0.747120       0.742090  0.790970   \n",
      "1     0.743582     0.723221  0.743551       0.742772       0.722592  0.742741   \n",
      "2     0.751301     0.743704  0.751288       0.751642       0.743949  0.751629   \n",
      "3     0.750448     0.744654  0.750438       0.749936       0.744298  0.749927   \n",
      "4     0.750959     0.745680  0.750951       0.751471       0.746477  0.751463   \n",
      "5     0.750959     0.744164  0.750948       0.750746       0.744948  0.750737   \n",
      "\n",
      "   mi_mrmr_accuracy  mi_mrmr_f1_score  mi_mrmr_auc  pca_accuracy  \\\n",
      "0          0.731060          0.723050     0.788740      0.735640   \n",
      "1          0.725800          0.705306     0.725770      0.742410   \n",
      "2          0.739403          0.733575     0.739394      0.743604   \n",
      "3          0.740512          0.735286     0.740503      0.741899   \n",
      "4          0.740384          0.735931     0.740377      0.744230   \n",
      "5          0.739616          0.741743     0.739620      0.754463   \n",
      "0          0.748740          0.742270     0.794050      0.733730   \n",
      "1          0.738124          0.715090     0.738089      0.742439   \n",
      "2          0.751215          0.742891     0.751202      0.744372   \n",
      "3          0.750874          0.744419     0.750864      0.740733   \n",
      "4          0.750320          0.744347     0.750310      0.746049   \n",
      "5          0.751215          0.745307     0.751206      0.753837   \n",
      "0          0.748070          0.742650     0.795480      0.736030   \n",
      "1          0.741194          0.719415     0.741161      0.744372   \n",
      "2          0.751898          0.743261     0.751883      0.747726   \n",
      "3          0.750064          0.744337     0.750055      0.740421   \n",
      "4          0.750618          0.744750     0.750609      0.748152   \n",
      "5          0.751087          0.745097     0.751078      0.753638   \n",
      "0          0.748620          0.740080     0.791470      0.739610   \n",
      "1          0.744648          0.724558     0.744617      0.745054   \n",
      "2          0.751898          0.743215     0.751883      0.749488   \n",
      "3          0.751258          0.744589     0.751247      0.741728   \n",
      "4          0.749168          0.744175     0.749160      0.749716   \n",
      "5          0.750576          0.745052     0.750567      0.752956   \n",
      "0          0.747540          0.742650     0.796430      0.732450   \n",
      "1          0.743156          0.723049     0.743125      0.745196   \n",
      "2          0.750618          0.743904     0.750607      0.748380   \n",
      "3          0.751301          0.744965     0.751290      0.745139   \n",
      "4          0.750917          0.744384     0.750906      0.751194   \n",
      "5          0.751301          0.745356     0.751291      0.753326   \n",
      "0          0.746470          0.739110     0.789150      0.735350   \n",
      "1          0.743539          0.723009     0.743508      0.745225   \n",
      "2          0.751429          0.743469     0.751415      0.748209   \n",
      "3          0.750320          0.744733     0.750311      0.744002   \n",
      "4          0.751770          0.745555     0.751759      0.750171   \n",
      "5          0.750661          0.744411     0.750651      0.753212   \n",
      "\n",
      "   pca_f1_score   pca_auc  \n",
      "0      0.735250  0.783890  \n",
      "1      0.727204  0.742410  \n",
      "2      0.743584  0.743604  \n",
      "3      0.739660  0.741899  \n",
      "4      0.743196  0.744230  \n",
      "5      0.750863  0.754463  \n",
      "0      0.729510  0.786190  \n",
      "1      0.723879  0.742439  \n",
      "2      0.742256  0.744372  \n",
      "3      0.737957  0.740733  \n",
      "4      0.742704  0.746049  \n",
      "5      0.748236  0.753837  \n",
      "0      0.726530  0.783760  \n",
      "1      0.725539  0.744372  \n",
      "2      0.745098  0.747726  \n",
      "3      0.736733  0.740421  \n",
      "4      0.745608  0.748152  \n",
      "5      0.747663  0.753638  \n",
      "0      0.734650  0.785760  \n",
      "1      0.726275  0.745054  \n",
      "2      0.746217  0.749488  \n",
      "3      0.738002  0.741728  \n",
      "4      0.747268  0.749716  \n",
      "5      0.746622  0.752956  \n",
      "0      0.723560  0.783310  \n",
      "1      0.726316  0.745196  \n",
      "2      0.743564  0.748380  \n",
      "3      0.741074  0.745139  \n",
      "4      0.748802  0.751194  \n",
      "5      0.747735  0.753326  \n",
      "0      0.725220  0.784370  \n",
      "1      0.726338  0.745225  \n",
      "2      0.743147  0.748209  \n",
      "3      0.739807  0.744002  \n",
      "4      0.747864  0.750171  \n",
      "5      0.747951  0.753212  \n",
      "   mi_accuracy  mi_f1_score    mi_auc  mrmr_accuracy  mrmr_f1_score  mrmr_auc  \\\n",
      "0     0.753860     0.755760  0.809480       0.759790       0.758150  0.810320   \n",
      "1     0.746886     0.733051  0.746886       0.750877       0.737662  0.750877   \n",
      "2     0.756491     0.758302  0.756491       0.764781       0.767039  0.764781   \n",
      "3     0.762719     0.764387  0.762719       0.765614       0.765911  0.765614   \n",
      "4     0.761228     0.762794  0.761228       0.766053       0.767213  0.766053   \n",
      "5     0.760877     0.768477  0.760877       0.766535       0.769534  0.766535   \n",
      "0     0.770790     0.772270  0.812010       0.766010       0.765540  0.813130   \n",
      "1     0.753596     0.738121  0.753596       0.754079       0.738417  0.754079   \n",
      "2     0.770351     0.770274  0.770351       0.770833       0.770598  0.770833   \n",
      "3     0.770307     0.771107  0.770307       0.770307       0.770976  0.770307   \n",
      "4     0.769956     0.771478  0.769956       0.770439       0.771982  0.770439   \n",
      "5     0.769956     0.772705  0.769956       0.770307       0.772940  0.770307   \n",
      "0     0.769390     0.772120  0.816670       0.767490       0.764390  0.814270   \n",
      "1     0.755000     0.740280  0.755000       0.755702       0.740656  0.755702   \n",
      "2     0.770307     0.771238  0.770307       0.771184       0.770732  0.771184   \n",
      "3     0.769430     0.769953  0.769430       0.770132       0.770915  0.770132   \n",
      "4     0.771491     0.772346  0.771491       0.770570       0.771871  0.770570   \n",
      "5     0.771184     0.773985  0.771184       0.770219       0.772686  0.770219   \n",
      "0     0.769560     0.772060  0.817370       0.767170       0.764810  0.810310   \n",
      "1     0.755132     0.740522  0.755132       0.757281       0.743006  0.757281   \n",
      "2     0.770570     0.770094  0.770570       0.771579       0.771980  0.771579   \n",
      "3     0.769781     0.769989  0.769781       0.770132       0.770924  0.770132   \n",
      "4     0.769693     0.770909  0.769693       0.769781       0.771928  0.769781   \n",
      "5     0.770877     0.773171  0.770877       0.771667       0.774347  0.771667   \n",
      "0     0.769110     0.770420  0.813520       0.767240       0.769070  0.814600   \n",
      "1     0.755044     0.741034  0.755044       0.755219       0.741026  0.755219   \n",
      "2     0.770746     0.770646  0.770746       0.771535       0.772353  0.771535   \n",
      "3     0.769518     0.770409  0.769518       0.769561       0.770504  0.769561   \n",
      "4     0.769781     0.771177  0.769781       0.769825       0.771161  0.769825   \n",
      "5     0.772237     0.774759  0.772237       0.772412       0.774393  0.772412   \n",
      "0     0.766710     0.767040  0.813530       0.766850       0.770880  0.814450   \n",
      "1     0.756140     0.741892  0.756140       0.754386       0.739919  0.754386   \n",
      "2     0.772061     0.771642  0.772061       0.772193       0.772554  0.772193   \n",
      "3     0.769649     0.771029  0.769649       0.770044       0.770887  0.770044   \n",
      "4     0.770614     0.771862  0.770614       0.769430       0.770476  0.769430   \n",
      "5     0.772018     0.774591  0.772018       0.773333       0.775945  0.773333   \n",
      "\n",
      "   mi_mrmr_accuracy  mi_mrmr_f1_score  mi_mrmr_auc  pca_accuracy  \\\n",
      "0          0.750710          0.751370     0.809050      0.751900   \n",
      "1          0.744254          0.731738     0.744254      0.746944   \n",
      "2          0.754430          0.754203     0.754430      0.753846   \n",
      "3          0.755965          0.757376     0.755965      0.751243   \n",
      "4          0.755746          0.756598     0.755746      0.755279   \n",
      "5          0.755526          0.763539     0.755526      0.765136   \n",
      "0          0.768330          0.769710     0.812810      0.747230   \n",
      "1          0.753553          0.737731     0.753553      0.747938   \n",
      "2          0.771447          0.770982     0.771447      0.753788   \n",
      "3          0.769868          0.771311     0.769868      0.747909   \n",
      "4          0.770175          0.772514     0.770175      0.755660   \n",
      "5          0.770000          0.772687     0.770000      0.766598   \n",
      "0          0.767100          0.769990     0.816350      0.749910   \n",
      "1          0.753465          0.737570     0.753465      0.749576   \n",
      "2          0.770351          0.770049     0.770351      0.756859   \n",
      "3          0.769474          0.770706     0.769474      0.747236   \n",
      "4          0.770044          0.771765     0.770044      0.755923   \n",
      "5          0.769868          0.772766     0.769868      0.765984   \n",
      "0          0.763550          0.761220     0.813650      0.747850   \n",
      "1          0.757237          0.742969     0.757237      0.750161   \n",
      "2          0.770219          0.770582     0.770219      0.759520   \n",
      "3          0.770088          0.770249     0.770088      0.750980   \n",
      "4          0.770263          0.771874     0.770263      0.757912   \n",
      "5          0.770833          0.773623     0.770833      0.765487   \n",
      "0          0.768200          0.768400     0.816550      0.753550   \n",
      "1          0.755658          0.741810     0.755658      0.750453   \n",
      "2          0.772237          0.772618     0.772237      0.760222   \n",
      "3          0.769868          0.771836     0.769868      0.750278   \n",
      "4          0.769781          0.770699     0.769781      0.758321   \n",
      "5          0.771535          0.774024     0.771535      0.765282   \n",
      "0          0.769290          0.770630     0.815360      0.751360   \n",
      "1          0.755570          0.741225     0.755570      0.750307   \n",
      "2          0.772281          0.773214     0.772281      0.761304   \n",
      "3          0.769868          0.770549     0.769868      0.751360   \n",
      "4          0.770307          0.771327     0.770307      0.757414   \n",
      "5          0.773333          0.775787     0.773333      0.764229   \n",
      "\n",
      "   pca_f1_score   pca_auc  \n",
      "0      0.752820  0.803690  \n",
      "1      0.736128  0.746932  \n",
      "2      0.758755  0.753852  \n",
      "3      0.754625  0.751247  \n",
      "4      0.758890  0.755284  \n",
      "5      0.768114  0.765140  \n",
      "0      0.748790  0.799220  \n",
      "1      0.734377  0.747923  \n",
      "2      0.756734  0.753791  \n",
      "3      0.748736  0.747910  \n",
      "4      0.757455  0.755662  \n",
      "5      0.768036  0.766600  \n",
      "0      0.753220  0.802180  \n",
      "1      0.735091  0.749560  \n",
      "2      0.759518  0.756862  \n",
      "3      0.748104  0.747237  \n",
      "4      0.757555  0.755925  \n",
      "5      0.766722  0.765985  \n",
      "0      0.753180  0.799900  \n",
      "1      0.735138  0.750144  \n",
      "2      0.761862  0.759523  \n",
      "3      0.751832  0.750981  \n",
      "4      0.760233  0.757915  \n",
      "5      0.766285  0.765488  \n",
      "0      0.750450  0.801780  \n",
      "1      0.735401  0.750437  \n",
      "2      0.761512  0.760224  \n",
      "3      0.751546  0.750279  \n",
      "4      0.760666  0.758324  \n",
      "5      0.766575  0.765284  \n",
      "0      0.748300  0.802390  \n",
      "1      0.735172  0.750290  \n",
      "2      0.762284  0.761306  \n",
      "3      0.752078  0.751361  \n",
      "4      0.760098  0.757418  \n",
      "5      0.767370  0.764233  \n",
      "   mi_accuracy  mi_f1_score    mi_auc  mrmr_accuracy  mrmr_f1_score  mrmr_auc  \\\n",
      "0     0.755050     0.752180  0.797200       0.751430       0.748510  0.794420   \n",
      "1     0.731899     0.710460  0.731865       0.729497       0.708250  0.729464   \n",
      "2     0.761350     0.761396  0.761350       0.759855       0.759221  0.759854   \n",
      "3     0.760897     0.760981  0.760897       0.759266       0.758402  0.759265   \n",
      "4     0.762121     0.762417  0.762121       0.759447       0.759210  0.759447   \n",
      "5     0.761531     0.761948  0.761532       0.760036       0.761744  0.760040   \n",
      "0     0.759990     0.762160  0.799630       0.762130       0.763230  0.800010   \n",
      "1     0.734662     0.713335  0.734629       0.734617       0.711550  0.734581   \n",
      "2     0.763117     0.762464  0.763116       0.762710       0.761720  0.762708   \n",
      "3     0.763480     0.763616  0.763480       0.762845       0.763202  0.762846   \n",
      "4     0.763389     0.764422  0.763391       0.763344       0.764042  0.763345   \n",
      "5     0.764658     0.766261  0.764661       0.764386       0.765744  0.764389   \n",
      "0     0.758960     0.757070  0.797480       0.760760       0.761070  0.799700   \n",
      "1     0.736158     0.715445  0.736125       0.735297       0.712526  0.735261   \n",
      "2     0.761758     0.762161  0.761759       0.763842       0.763343  0.763841   \n",
      "3     0.763163     0.763870  0.763164       0.763253       0.763711  0.763254   \n",
      "4     0.763299     0.763983  0.763300       0.763525       0.764565  0.763527   \n",
      "5     0.764703     0.766093  0.764706       0.764431       0.765727  0.764434   \n",
      "0     0.753690     0.749300  0.798130       0.762240       0.764580  0.800110   \n",
      "1     0.735886     0.715400  0.735853       0.736112       0.715292  0.736079   \n",
      "2     0.762619     0.762810  0.762619       0.763570       0.762946  0.763569   \n",
      "3     0.763163     0.764717  0.763166       0.763480       0.764188  0.763481   \n",
      "4     0.761214     0.762605  0.761217       0.762392       0.762947  0.762394   \n",
      "5     0.764522     0.765451  0.764524       0.764658       0.765982  0.764661   \n",
      "0     0.759810     0.762070  0.799820       0.758360       0.754660  0.801060   \n",
      "1     0.736747     0.716446  0.736714       0.737290       0.717119  0.737258   \n",
      "2     0.761849     0.762136  0.761849       0.761803       0.762037  0.761804   \n",
      "3     0.763570     0.763985  0.763571       0.763208       0.764526  0.763211   \n",
      "4     0.762166     0.763489  0.762169       0.762891       0.764317  0.762894   \n",
      "5     0.764295     0.765667  0.764298       0.764341       0.765830  0.764344   \n",
      "0     0.759940     0.760580  0.800450       0.759810       0.760490  0.799030   \n",
      "1     0.736837     0.716865  0.736806       0.736747       0.716530  0.736715   \n",
      "2     0.762574     0.763020  0.762575       0.762030       0.762645  0.762031   \n",
      "3     0.761622     0.761708  0.761622       0.762483       0.762765  0.762484   \n",
      "4     0.762755     0.763520  0.762756       0.762574       0.764203  0.762577   \n",
      "5     0.763888     0.765017  0.763890       0.763797       0.765141  0.763800   \n",
      "\n",
      "   mi_mrmr_accuracy  mi_mrmr_f1_score  mi_mrmr_auc  pca_accuracy  \\\n",
      "0          0.740790          0.737160     0.790620      0.747770   \n",
      "1          0.725782          0.706555     0.725752      0.736012   \n",
      "2          0.753330          0.752028     0.753328      0.750000   \n",
      "3          0.753240          0.752674     0.753239      0.743776   \n",
      "4          0.755913          0.756029     0.755913      0.750544   \n",
      "5          0.748165          0.756051     0.748180      0.766616   \n",
      "0          0.759770          0.761090     0.799360      0.738740   \n",
      "1          0.734255          0.711752     0.734219      0.736163   \n",
      "2          0.762302          0.761474     0.762300      0.747160   \n",
      "3          0.761803          0.762912     0.761806      0.741843   \n",
      "4          0.763163          0.763908     0.763164      0.747583   \n",
      "5          0.764069          0.765501     0.764072      0.765468   \n",
      "0          0.756460          0.754520     0.796150      0.741980   \n",
      "1          0.734572          0.712110     0.734537      0.737341   \n",
      "2          0.763163          0.762576     0.763162      0.750121   \n",
      "3          0.762528          0.763829     0.762531      0.742900   \n",
      "4          0.762981          0.763528     0.762983      0.748882   \n",
      "5          0.764205          0.765564     0.764208      0.764804   \n",
      "0          0.758510          0.759430     0.798170      0.741470   \n",
      "1          0.735342          0.714497     0.735309      0.739728   \n",
      "2          0.762800          0.762080     0.762799      0.750302   \n",
      "3          0.762891          0.764148     0.762893      0.743867   \n",
      "4          0.762256          0.763135     0.762258      0.750483   \n",
      "5          0.764839          0.766226     0.764842      0.764562   \n",
      "0          0.758000          0.754340     0.799160      0.743180   \n",
      "1          0.736747          0.716342     0.736714      0.739909   \n",
      "2          0.762710          0.763048     0.762710      0.750060   \n",
      "3          0.762392          0.762345     0.762392      0.741843   \n",
      "4          0.763117          0.764486     0.763120      0.749637   \n",
      "5          0.764069          0.765474     0.764072      0.764683   \n",
      "0          0.758270          0.757820     0.797760      0.742180   \n",
      "1          0.736611          0.716083     0.736578      0.739909   \n",
      "2          0.762302          0.762791     0.762303      0.750695   \n",
      "3          0.760897          0.761556     0.760899      0.744290   \n",
      "4          0.763072          0.764992     0.763076      0.748852   \n",
      "5          0.763752          0.764919     0.763754      0.764985   \n",
      "\n",
      "   pca_f1_score   pca_auc  \n",
      "0      0.749110  0.793030  \n",
      "1      0.721295  0.736012  \n",
      "2      0.751397  0.750000  \n",
      "3      0.743657  0.743776  \n",
      "4      0.751812  0.750544  \n",
      "5      0.769182  0.766616  \n",
      "0      0.738200  0.786360  \n",
      "1      0.718765  0.736163  \n",
      "2      0.747278  0.747160  \n",
      "3      0.740253  0.741843  \n",
      "4      0.746944  0.747583  \n",
      "5      0.767100  0.765468  \n",
      "0      0.743710  0.789000  \n",
      "1      0.719428  0.737341  \n",
      "2      0.749576  0.750121  \n",
      "3      0.740512  0.742900  \n",
      "4      0.747900  0.748882  \n",
      "5      0.765987  0.764804  \n",
      "0      0.737400  0.788970  \n",
      "1      0.721593  0.739728  \n",
      "2      0.749886  0.750302  \n",
      "3      0.740672  0.743867  \n",
      "4      0.749291  0.750483  \n",
      "5      0.766483  0.764562  \n",
      "0      0.740670  0.787550  \n",
      "1      0.721786  0.739909  \n",
      "2      0.748758  0.750060  \n",
      "3      0.737993  0.741843  \n",
      "4      0.748926  0.749637  \n",
      "5      0.767346  0.764683  \n",
      "0      0.739440  0.788850  \n",
      "1      0.721786  0.739909  \n",
      "2      0.748624  0.750695  \n",
      "3      0.741084  0.744290  \n",
      "4      0.747593  0.748852  \n",
      "5      0.768186  0.764985  \n"
     ]
    }
   ],
   "source": [
    "def getting_mean(length, df=shopper_df):\n",
    "    percentiles_list = [10, 20, 30, 50, 75, 90]\n",
    "    models_list = ['ft_transformer', 'lr', 'rfc', 'xgbc', 'lgbm', 'svm']\n",
    "    all_df = list()\n",
    "    for j in percentiles_list:\n",
    "        means = list()\n",
    "        \n",
    "        for i in models_list:\n",
    "            model = df[(df.percentiles == j) & (df.models == i) & (df.length_text == length)]\n",
    "            mean_val = list(model[shopper_df_float].mean())\n",
    "            means.append(mean_val)\n",
    "        means_df = pd.DataFrame(means, columns=shopper_df_float).reset_index()\n",
    "        means_df['models_name'] = pd.Series(['ft_transformer', 'lr', 'rfc', 'xgbc', 'lgbm', 'svm'])\n",
    "        means_df['percentiles_name'] = pd.Series([j] * 6)\n",
    "        all_df.append(means_df)\n",
    "    all_df = pd.concat(all_df)\n",
    "    all_df.drop(['index', 'models_name', 'percentiles_name'], axis=1, inplace=True)\n",
    "    return all_df\n",
    "\n",
    "feature_reduction_df_8 = getting_mean(8)\n",
    "feature_reduction_df_9 = getting_mean(9)\n",
    "feature_reduction_df_10 = getting_mean(10)\n",
    "feature_reduction_df_11 = getting_mean(11)\n",
    "feature_reduction_df_12 = getting_mean(12)\n",
    "feature_reduction_df_13 = getting_mean(13)\n",
    "feature_reduction_df_14 = getting_mean(14)\n",
    "feature_reduction_df_15 = getting_mean(15)\n",
    "feature_reduction_df_16 = getting_mean(16)\n",
    "feature_reduction_df_17 = getting_mean(17)\n",
    "\n",
    "print(feature_reduction_df_8)\n",
    "print(feature_reduction_df_9)\n",
    "print(feature_reduction_df_10)\n",
    "print(feature_reduction_df_11)\n",
    "print(feature_reduction_df_12)\n",
    "print(feature_reduction_df_13)\n",
    "print(feature_reduction_df_14)\n",
    "print(feature_reduction_df_15)\n",
    "print(feature_reduction_df_16)\n",
    "print(feature_reduction_df_17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================ 8= ===========================================================\n",
      "[('pca_f1_score', 0.7911081501045316), ('mi_f1_score', 0.29461591182037317), ('mrmr_f1_score', 0.23603003166897715), ('mi_mrmr_f1_score', 0.20108166413309744)]\n",
      "[('mi_auc', 0.8677006641662602), ('mrmr_auc', 0.7268634557123935), ('mi_mrmr_auc', 0.6074493353791115), ('pca_auc', 0.22209597699953817)]\n",
      "[('mi_accuracy', 0.879898740940194), ('mrmr_accuracy', 0.8071758571719463), ('mi_mrmr_accuracy', 0.5758207580636645), ('pca_accuracy', 0.21177447779473876)]\n",
      "============================================================ 9= ===========================================================\n",
      "[('mi_f1_score', 0.596274045565255), ('pca_f1_score', 0.5384466290923544), ('mi_mrmr_f1_score', 0.5120449328799612), ('mrmr_f1_score', 0.44066401565338287)]\n",
      "[('mrmr_auc', 0.830529443284165), ('mi_auc', 0.8226647972047744), ('mi_mrmr_auc', 0.6894492762657166), ('pca_auc', 0.09420808853068481)]\n",
      "[('mrmr_accuracy', 0.8737303269231951), ('mi_accuracy', 0.8477249294018443), ('mi_mrmr_accuracy', 0.682713360681692), ('pca_accuracy', 0.11814503540460382)]\n",
      "============================================================ 10 ============================================================\n",
      "[('pca_f1_score', 0.7881163899097277), ('mi_f1_score', 0.2585685560581284), ('mrmr_f1_score', 0.21864974500623705), ('mi_mrmr_f1_score', 0.1849736587077974)]\n",
      "[('pca_auc', 0.6181569522690661), ('mi_auc', 0.3936779329879072), ('mrmr_auc', 0.3407133511917831), ('mi_mrmr_auc', 0.32637715578325577)]\n",
      "[('pca_accuracy', 0.560110275885455), ('mi_accuracy', 0.444168996402764), ('mrmr_accuracy', 0.42537414724626504), ('mi_mrmr_accuracy', 0.3936195679144555)]\n",
      "============================================================ 11 ============================================================\n",
      "[('mi_f1_score', 0.857653464605965), ('mrmr_f1_score', 0.8534834376297527), ('mi_mrmr_f1_score', 0.7649717094891394), ('pca_f1_score', 0.16283531463910772)]\n",
      "[('mrmr_auc', 0.9173525980131926), ('mi_auc', 0.9162693024148708), ('mi_mrmr_auc', 0.8684013346091135), ('pca_auc', 0.0)]\n",
      "[('mrmr_accuracy', 0.9238548512359742), ('mi_accuracy', 0.918508462442262), ('mi_mrmr_accuracy', 0.8157109810952973), ('pca_accuracy', 0.0)]\n",
      "============================================================ 12 ============================================================\n",
      "[('pca_f1_score', 0.6800789546045933), ('mi_mrmr_f1_score', 0.3077408283657379), ('mi_f1_score', 0.3048267277360269), ('mrmr_f1_score', 0.272325063845423)]\n",
      "[('mi_auc', 0.5639462298780746), ('mrmr_auc', 0.507439001047858), ('pca_auc', 0.49259227112404474), ('mi_mrmr_auc', 0.4858154516021131)]\n",
      "[('mi_accuracy', 0.5851542875886837), ('mrmr_accuracy', 0.5210995320465495), ('mi_mrmr_accuracy', 0.4994229310493262), ('pca_accuracy', 0.4804283360320315)]\n",
      "============================================================ 13 ============================================================\n",
      "[('mrmr_f1_score', 0.8399389309900994), ('mi_f1_score', 0.8058927183253617), ('mi_mrmr_f1_score', 0.7272198131394785), ('pca_f1_score', 0.16421244928711104)]\n",
      "[('mrmr_auc', 0.9256156670850134), ('mi_auc', 0.8051418429821681), ('mi_mrmr_auc', 0.7295408044909877), ('pca_auc', 0.11973764013805975)]\n",
      "[('mrmr_accuracy', 0.9131794336860277), ('mi_accuracy', 0.8055765288730702), ('mi_mrmr_accuracy', 0.7399002210399889), ('pca_accuracy', 0.10967230997786631)]\n",
      "============================================================ 14 ============================================================\n",
      "[('mi_f1_score', 0.6333172249832683), ('mrmr_f1_score', 0.5842289529716372), ('mi_mrmr_f1_score', 0.5823980733922816), ('pca_f1_score', 0.40873419947453504)]\n",
      "[('mrmr_auc', 0.7570714440693607), ('mi_auc', 0.7279906662506499), ('mi_mrmr_auc', 0.6698480370467648), ('pca_auc', 0.27258221958651035)]\n",
      "[('mrmr_accuracy', 0.7838030862696178), ('mi_accuracy', 0.7556913916470701), ('mi_mrmr_accuracy', 0.7072144683963624), ('pca_accuracy', 0.25104805895663446)]\n",
      "============================================================ 15 ============================================================\n",
      "[('mrmr_f1_score', 0.6436849120775878), ('mi_f1_score', 0.5537907733484572), ('mi_mrmr_f1_score', 0.5038638524993325), ('pca_f1_score', 0.47315714169360734)]\n",
      "[('mrmr_auc', 0.7053684293096769), ('mi_auc', 0.5750276974710465), ('mi_mrmr_auc', 0.5205196659866878), ('pca_auc', 0.41294231681498045)]\n",
      "[('mrmr_accuracy', 0.7752742452019128), ('mi_accuracy', 0.6258302506175467), ('mi_mrmr_accuracy', 0.5567110373768754), ('pca_accuracy', 0.39660616106517044)]\n",
      "============================================================ 16 ============================================================\n",
      "[('mi_f1_score', 0.8563447114834456), ('mrmr_f1_score', 0.8539730637134986), ('mi_mrmr_f1_score', 0.7496677942114502), ('pca_f1_score', 0.09212355713300817)]\n",
      "[('mrmr_auc', 0.9010475555519086), ('mi_auc', 0.8445727864838921), ('mi_mrmr_auc', 0.7620238260103911), ('pca_auc', 0.11437635381003089)]\n",
      "[('mrmr_accuracy', 0.9191730977644899), ('mi_accuracy', 0.8457789508964711), ('mi_mrmr_accuracy', 0.7521193870092595), ('pca_accuracy', 0.10817869016244733)]\n",
      "============================================================ 17 ============================================================\n",
      "[('mrmr_f1_score', 0.7946904929118243), ('mi_f1_score', 0.7828586529700307), ('mi_mrmr_f1_score', 0.7007248496148043), ('pca_f1_score', 0.23375003447225057)]\n",
      "[('mi_auc', 0.8763334328098578), ('mrmr_auc', 0.8543043189772556), ('mi_mrmr_auc', 0.706394488300726), ('pca_auc', 0.23641055743838194)]\n",
      "[('mrmr_accuracy', 0.8657651237175338), ('mi_accuracy', 0.8571630663860175), ('mi_mrmr_accuracy', 0.7041540785611452), ('pca_accuracy', 0.22509134190507224)]\n"
     ]
    }
   ],
   "source": [
    "print(\"============================================================ 8= ===========================================================\")\n",
    "feature_reduction_df_8_f1 = feature_reduction_df_8[['mi_f1_score', 'mrmr_f1_score', 'mi_mrmr_f1_score', 'pca_f1_score']].reset_index(drop=True).T\n",
    "feature_reduction_df_8_auc = feature_reduction_df_8[['mi_auc', 'mrmr_auc', 'mi_mrmr_auc', 'pca_auc']].reset_index(drop=True).T\n",
    "feature_reduction_df_8_accuracy = feature_reduction_df_8[['mi_accuracy', 'mrmr_accuracy', 'mi_mrmr_accuracy', 'pca_accuracy']].reset_index(drop=True).T\n",
    "print(mcdm.rank(feature_reduction_df_8_f1.to_numpy(), s_method='TOPSIS', alt_names=['mi_f1_score', 'mrmr_f1_score', 'mi_mrmr_f1_score', 'pca_f1_score']))\n",
    "print(mcdm.rank(feature_reduction_df_8_auc.to_numpy(), s_method='TOPSIS', alt_names=['mi_auc', 'mrmr_auc', 'mi_mrmr_auc', 'pca_auc']))\n",
    "print(mcdm.rank(feature_reduction_df_8_accuracy.to_numpy(), s_method='TOPSIS', alt_names=['mi_accuracy', 'mrmr_accuracy', 'mi_mrmr_accuracy', 'pca_accuracy']))\n",
    "\n",
    "print(\"============================================================ 9= ===========================================================\")\n",
    "feature_reduction_df_9_f1 = feature_reduction_df_9[['mi_f1_score', 'mrmr_f1_score', 'mi_mrmr_f1_score', 'pca_f1_score']].reset_index(drop=True).T\n",
    "feature_reduction_df_9_auc = feature_reduction_df_9[['mi_auc', 'mrmr_auc', 'mi_mrmr_auc', 'pca_auc']].reset_index(drop=True).T\n",
    "feature_reduction_df_9_accuracy = feature_reduction_df_9[['mi_accuracy', 'mrmr_accuracy', 'mi_mrmr_accuracy', 'pca_accuracy']].reset_index(drop=True).T\n",
    "print(mcdm.rank(feature_reduction_df_9_f1.to_numpy(), s_method='TOPSIS', alt_names=['mi_f1_score', 'mrmr_f1_score', 'mi_mrmr_f1_score', 'pca_f1_score']))\n",
    "print(mcdm.rank(feature_reduction_df_9_auc.to_numpy(), s_method='TOPSIS', alt_names=['mi_auc', 'mrmr_auc', 'mi_mrmr_auc', 'pca_auc']))\n",
    "print(mcdm.rank(feature_reduction_df_9_accuracy.to_numpy(), s_method='TOPSIS', alt_names=['mi_accuracy', 'mrmr_accuracy', 'mi_mrmr_accuracy', 'pca_accuracy']))\n",
    "\n",
    "print(\"============================================================ 10 ============================================================\")\n",
    "feature_reduction_df_10_f1 = feature_reduction_df_10[['mi_f1_score', 'mrmr_f1_score', 'mi_mrmr_f1_score', 'pca_f1_score']].reset_index(drop=True).T\n",
    "feature_reduction_df_10_auc = feature_reduction_df_10[['mi_auc', 'mrmr_auc', 'mi_mrmr_auc', 'pca_auc']].reset_index(drop=True).T\n",
    "feature_reduction_df_10_accuracy = feature_reduction_df_10[['mi_accuracy', 'mrmr_accuracy', 'mi_mrmr_accuracy', 'pca_accuracy']].reset_index(drop=True).T\n",
    "print(mcdm.rank(feature_reduction_df_10_f1.to_numpy(), s_method='TOPSIS', alt_names=['mi_f1_score', 'mrmr_f1_score', 'mi_mrmr_f1_score', 'pca_f1_score']))\n",
    "print(mcdm.rank(feature_reduction_df_10_auc.to_numpy(), s_method='TOPSIS', alt_names=['mi_auc', 'mrmr_auc', 'mi_mrmr_auc', 'pca_auc']))\n",
    "print(mcdm.rank(feature_reduction_df_10_accuracy.to_numpy(), s_method='TOPSIS', alt_names=['mi_accuracy', 'mrmr_accuracy', 'mi_mrmr_accuracy', 'pca_accuracy']))\n",
    "\n",
    "print(\"============================================================ 11 ============================================================\")\n",
    "feature_reduction_df_11_f1 = feature_reduction_df_11[['mi_f1_score', 'mrmr_f1_score', 'mi_mrmr_f1_score', 'pca_f1_score']].reset_index(drop=True).T\n",
    "feature_reduction_df_11_auc = feature_reduction_df_11[['mi_auc', 'mrmr_auc', 'mi_mrmr_auc', 'pca_auc']].reset_index(drop=True).T\n",
    "feature_reduction_df_11_accuracy = feature_reduction_df_11[['mi_accuracy', 'mrmr_accuracy', 'mi_mrmr_accuracy', 'pca_accuracy']].reset_index(drop=True).T\n",
    "print(mcdm.rank(feature_reduction_df_11_f1.to_numpy(), s_method='TOPSIS', alt_names=['mi_f1_score', 'mrmr_f1_score', 'mi_mrmr_f1_score', 'pca_f1_score']))\n",
    "print(mcdm.rank(feature_reduction_df_11_auc.to_numpy(), s_method='TOPSIS', alt_names=['mi_auc', 'mrmr_auc', 'mi_mrmr_auc', 'pca_auc']))\n",
    "print(mcdm.rank(feature_reduction_df_11_accuracy.to_numpy(), s_method='TOPSIS', alt_names=['mi_accuracy', 'mrmr_accuracy', 'mi_mrmr_accuracy', 'pca_accuracy']))\n",
    "\n",
    "print(\"============================================================ 12 ============================================================\")\n",
    "feature_reduction_df_12_f1 = feature_reduction_df_12[['mi_f1_score', 'mrmr_f1_score', 'mi_mrmr_f1_score', 'pca_f1_score']].reset_index(drop=True).T\n",
    "feature_reduction_df_12_auc = feature_reduction_df_12[['mi_auc', 'mrmr_auc', 'mi_mrmr_auc', 'pca_auc']].reset_index(drop=True).T\n",
    "feature_reduction_df_12_accuracy = feature_reduction_df_12[['mi_accuracy', 'mrmr_accuracy', 'mi_mrmr_accuracy', 'pca_accuracy']].reset_index(drop=True).T\n",
    "print(mcdm.rank(feature_reduction_df_12_f1.to_numpy(), s_method='TOPSIS', alt_names=['mi_f1_score', 'mrmr_f1_score', 'mi_mrmr_f1_score', 'pca_f1_score']))\n",
    "print(mcdm.rank(feature_reduction_df_12_auc.to_numpy(), s_method='TOPSIS', alt_names=['mi_auc', 'mrmr_auc', 'mi_mrmr_auc', 'pca_auc']))\n",
    "print(mcdm.rank(feature_reduction_df_12_accuracy.to_numpy(), s_method='TOPSIS', alt_names=['mi_accuracy', 'mrmr_accuracy', 'mi_mrmr_accuracy', 'pca_accuracy']))\n",
    "\n",
    "print(\"============================================================ 13 ============================================================\")\n",
    "feature_reduction_df_13_f1 = feature_reduction_df_13[['mi_f1_score', 'mrmr_f1_score', 'mi_mrmr_f1_score', 'pca_f1_score']].reset_index(drop=True).T\n",
    "feature_reduction_df_13_auc = feature_reduction_df_13[['mi_auc', 'mrmr_auc', 'mi_mrmr_auc', 'pca_auc']].reset_index(drop=True).T\n",
    "feature_reduction_df_13_accuracy = feature_reduction_df_13[['mi_accuracy', 'mrmr_accuracy', 'mi_mrmr_accuracy', 'pca_accuracy']].reset_index(drop=True).T\n",
    "print(mcdm.rank(feature_reduction_df_13_f1.to_numpy(), s_method='TOPSIS', alt_names=['mi_f1_score', 'mrmr_f1_score', 'mi_mrmr_f1_score', 'pca_f1_score']))\n",
    "print(mcdm.rank(feature_reduction_df_13_auc.to_numpy(), s_method='TOPSIS', alt_names=['mi_auc', 'mrmr_auc', 'mi_mrmr_auc', 'pca_auc']))\n",
    "print(mcdm.rank(feature_reduction_df_13_accuracy.to_numpy(), s_method='TOPSIS', alt_names=['mi_accuracy', 'mrmr_accuracy', 'mi_mrmr_accuracy', 'pca_accuracy']))\n",
    "\n",
    "print(\"============================================================ 14 ============================================================\")\n",
    "feature_reduction_df_14_f1 = feature_reduction_df_14[['mi_f1_score', 'mrmr_f1_score', 'mi_mrmr_f1_score', 'pca_f1_score']].reset_index(drop=True).T\n",
    "feature_reduction_df_14_auc = feature_reduction_df_14[['mi_auc', 'mrmr_auc', 'mi_mrmr_auc', 'pca_auc']].reset_index(drop=True).T\n",
    "feature_reduction_df_14_accuracy = feature_reduction_df_14[['mi_accuracy', 'mrmr_accuracy', 'mi_mrmr_accuracy', 'pca_accuracy']].reset_index(drop=True).T\n",
    "print(mcdm.rank(feature_reduction_df_14_f1.to_numpy(), s_method='TOPSIS', alt_names=['mi_f1_score', 'mrmr_f1_score', 'mi_mrmr_f1_score', 'pca_f1_score']))\n",
    "print(mcdm.rank(feature_reduction_df_14_auc.to_numpy(), s_method='TOPSIS', alt_names=['mi_auc', 'mrmr_auc', 'mi_mrmr_auc', 'pca_auc']))\n",
    "print(mcdm.rank(feature_reduction_df_14_accuracy.to_numpy(), s_method='TOPSIS', alt_names=['mi_accuracy', 'mrmr_accuracy', 'mi_mrmr_accuracy', 'pca_accuracy']))\n",
    "\n",
    "print(\"============================================================ 15 ============================================================\")\n",
    "feature_reduction_df_15_f1 = feature_reduction_df_15[['mi_f1_score', 'mrmr_f1_score', 'mi_mrmr_f1_score', 'pca_f1_score']].reset_index(drop=True).T\n",
    "feature_reduction_df_15_auc = feature_reduction_df_15[['mi_auc', 'mrmr_auc', 'mi_mrmr_auc', 'pca_auc']].reset_index(drop=True).T\n",
    "feature_reduction_df_15_accuracy = feature_reduction_df_15[['mi_accuracy', 'mrmr_accuracy', 'mi_mrmr_accuracy', 'pca_accuracy']].reset_index(drop=True).T\n",
    "print(mcdm.rank(feature_reduction_df_15_f1.to_numpy(), s_method='TOPSIS', alt_names=['mi_f1_score', 'mrmr_f1_score', 'mi_mrmr_f1_score', 'pca_f1_score']))\n",
    "print(mcdm.rank(feature_reduction_df_15_auc.to_numpy(), s_method='TOPSIS', alt_names=['mi_auc', 'mrmr_auc', 'mi_mrmr_auc', 'pca_auc']))\n",
    "print(mcdm.rank(feature_reduction_df_15_accuracy.to_numpy(), s_method='TOPSIS', alt_names=['mi_accuracy', 'mrmr_accuracy', 'mi_mrmr_accuracy', 'pca_accuracy']))\n",
    "\n",
    "print(\"============================================================ 16 ============================================================\")\n",
    "feature_reduction_df_16_f1 = feature_reduction_df_16[['mi_f1_score', 'mrmr_f1_score', 'mi_mrmr_f1_score', 'pca_f1_score']].reset_index(drop=True).T\n",
    "feature_reduction_df_16_auc = feature_reduction_df_16[['mi_auc', 'mrmr_auc', 'mi_mrmr_auc', 'pca_auc']].reset_index(drop=True).T\n",
    "feature_reduction_df_16_accuracy = feature_reduction_df_16[['mi_accuracy', 'mrmr_accuracy', 'mi_mrmr_accuracy', 'pca_accuracy']].reset_index(drop=True).T\n",
    "print(mcdm.rank(feature_reduction_df_16_f1.to_numpy(), s_method='TOPSIS', alt_names=['mi_f1_score', 'mrmr_f1_score', 'mi_mrmr_f1_score', 'pca_f1_score']))\n",
    "print(mcdm.rank(feature_reduction_df_16_auc.to_numpy(), s_method='TOPSIS', alt_names=['mi_auc', 'mrmr_auc', 'mi_mrmr_auc', 'pca_auc']))\n",
    "print(mcdm.rank(feature_reduction_df_16_accuracy.to_numpy(), s_method='TOPSIS', alt_names=['mi_accuracy', 'mrmr_accuracy', 'mi_mrmr_accuracy', 'pca_accuracy']))\n",
    "\n",
    "print(\"============================================================ 17 ============================================================\")\n",
    "feature_reduction_df_17_f1 = feature_reduction_df_17[['mi_f1_score', 'mrmr_f1_score', 'mi_mrmr_f1_score', 'pca_f1_score']].reset_index(drop=True).T\n",
    "feature_reduction_df_17_auc = feature_reduction_df_17[['mi_auc', 'mrmr_auc', 'mi_mrmr_auc', 'pca_auc']].reset_index(drop=True).T\n",
    "feature_reduction_df_17_accuracy = feature_reduction_df_17[['mi_accuracy', 'mrmr_accuracy', 'mi_mrmr_accuracy', 'pca_accuracy']].reset_index(drop=True).T\n",
    "print(mcdm.rank(feature_reduction_df_17_f1.to_numpy(), s_method='TOPSIS', alt_names=['mi_f1_score', 'mrmr_f1_score', 'mi_mrmr_f1_score', 'pca_f1_score']))\n",
    "print(mcdm.rank(feature_reduction_df_17_auc.to_numpy(), s_method='TOPSIS', alt_names=['mi_auc', 'mrmr_auc', 'mi_mrmr_auc', 'pca_auc']))\n",
    "print(mcdm.rank(feature_reduction_df_17_accuracy.to_numpy(), s_method='TOPSIS', alt_names=['mi_accuracy', 'mrmr_accuracy', 'mi_mrmr_accuracy', 'pca_accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shopper-intent-prediction-L5e-nQUd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
