{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.tree import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.svm import *\n",
    "from sklearn.decomposition import *\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import re\n",
    "import ast\n",
    "from autokeras import StructuredDataClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13 14 15 16 17\n",
    "length_text = 13\n",
    "directory_dataframes = '/kaggle/input/shorty/short/subsamples/{}/'.format(length_text)\n",
    "directory_features = '/kaggle/input/shorty/short/features/{}/'.format(length_text)\n",
    "\n",
    "\n",
    "def sorted_alphanumeric(data):\n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
    "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ] \n",
    "    return sorted(data, key=alphanum_key)\n",
    "\n",
    "def get_sample_df(directory=directory_dataframes):\n",
    "    list_dataframes = []\n",
    "    filename_list = []\n",
    "    dir_list = sorted_alphanumeric(os.listdir(directory))\n",
    "    for filename in dir_list:\n",
    "        f = os.path.join(directory, filename)\n",
    "        if os.path.isfile(f):\n",
    "            list_dataframes.append(pd.read_csv(f))\n",
    "            filename_list.append(filename)\n",
    "            \n",
    "    return list_dataframes, filename_list\n",
    "\n",
    "def get_features(regex_str, directory=directory_features):\n",
    "    regex = re.compile('/kaggle/input/shorty/short/features/{}/{}'.format(length_text, regex_str))\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        f = os.path.join(directory, filename)\n",
    "#         print(f)\n",
    "        if regex.match(f):\n",
    "            file1 = open(f)\n",
    "            feat_list = file1.read().splitlines()\n",
    "            \n",
    "            #txt file converts everything to string, so we need to convert it back to list\n",
    "            for i in range(len(feat_list)):\n",
    "                #adding ; to be used a separator for list\n",
    "                if i<len(feat_list):\n",
    "                    new_val = feat_list[i].replace('y','y;').replace(') ','); ').replace('4 ', '4; ').replace('5 ', '5; ')\n",
    "                    feat_list[i] = new_val\n",
    "                \n",
    "    for val in feat_list:\n",
    "        #separating the string into a list of features\n",
    "        new_val = val.split('; ')\n",
    "        feat_list[feat_list.index(val)] = new_val\n",
    "        \n",
    "    return feat_list\n",
    "\n",
    "list_sample_dataframes, filename_sample_list = get_sample_df(directory_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train_predict(regex_str, dataframes=list_sample_dataframes, params=None):\n",
    "    \n",
    "    feat_list = get_features(regex_str)\n",
    "    \n",
    "    accuracy_list = []\n",
    "    f1_score_list = []\n",
    "    auc_list = []\n",
    "    \n",
    "    \n",
    "    for i, (sample, feat) in enumerate(zip(dataframes, feat_list)):\n",
    "        print(i)\n",
    "        \n",
    "        feat[len(feat)-1] = feat[len(feat)-1].replace('y;', 'y')\n",
    "        x = sample[feat]\n",
    "        x = x.rename(columns = lambda a:re.sub('[^A-Za-z0-9_]+', '', a))\n",
    "        \n",
    "\n",
    "        model = StructuredDataClassifier(max_trials=5, overwrite=True, column_names=feat)\n",
    "        \n",
    "        y = sample['conversion_class']\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        \n",
    "        loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "        print('Accuracy: %.3f' % acc)\n",
    "        \n",
    "        accuracy_list.append(accuracy_score(y_test, y_pred))\n",
    "        f1_score_list.append(f1_score(y_test, y_pred))\n",
    "        auc_list.append(roc_auc_score(y_test, y_pred))\n",
    "        \n",
    "\n",
    "    print('Average Accuracy', np.mean(accuracy_list))\n",
    "    print('Average F1 Score', np.mean(f1_score_list))\n",
    "    print('Average AUC', np.mean(auc_list)) \n",
    "    \n",
    "    print('Max Accuracy', max(accuracy_list))\n",
    "    print('Max F1 Score', max(f1_score_list))\n",
    "    print('Max AUC', max(auc_list))  \n",
    "    \n",
    "    print(accuracy_list)\n",
    "    print(auc_list)\n",
    "    best_accuracy_index = accuracy_list.index(max(accuracy_list))\n",
    "    best_f1_score_index = f1_score_list.index(max(f1_score_list))\n",
    "    best_auc_index = auc_list.index(max(auc_list))\n",
    "    \n",
    "    print('Best Sample Index based on Max Accuracy', best_accuracy_index)\n",
    "    print('Best Sample Index based on Max F1 Score', best_f1_score_index)\n",
    "    print('Best Sample Index based on Max AUC', best_auc_index)\n",
    "    \n",
    "    print('Best Features based on Max Accuracy', feat_list[best_accuracy_index])\n",
    "    print('Best Features based on Max F1 Score', feat_list[best_f1_score_index])\n",
    "    print('Best Features based on Max AUC', feat_list[best_auc_index])\n",
    "    \n",
    "    return accuracy_list, f1_score_list, auc_list \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list_nas_10_mi, f1_score_list_nas_10_mi, auc_list_nas_10_mi = model_train_predict('mi_feat_list_10')\n",
    "accuracy_list_nas_20_mi, f1_score_list_nas_20_mi, auc_list_nas_20_mi = model_train_predict('mi_feat_list_20')\n",
    "accuracy_list_nas_30_mi, f1_score_list_nas_30_mi, auc_list_nas_30_mi = model_train_predict('mi_feat_list_30')\n",
    "accuracy_list_nas_50_mi, f1_score_list_nas_50_mi, auc_list_nas_50_mi = model_train_predict('mi_feat_list_50')\n",
    "accuracy_list_nas_75_mi, f1_score_list_nas_75_mi, auc_list_nas_75_mi = model_train_predict('mi_feat_list_75')\n",
    "accuracy_list_nas_90_mi, f1_score_list_nas_90_mi, auc_list_nas_90_mi = model_train_predict('mi_feat_list_90')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mRMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list_nas_10_mrmr, f1_score_list_nas_10_mrmr, auc_list_nas_10_mrmr = model_train_predict('mrmr_feat_list_10')\n",
    "accuracy_list_nas_20_mrmr, f1_score_list_nas_20_mrmr, auc_list_nas_20_mrmr = model_train_predict('mrmr_feat_list_20')\n",
    "accuracy_list_nas_30_mrmr, f1_score_list_nas_30_mrmr, auc_list_nas_30_mrmr = model_train_predict('mrmr_feat_list_30')\n",
    "accuracy_list_nas_50_mrmr, f1_score_list_nas_50_mrmr, auc_list_nas_50_mrmr = model_train_predict('mrmr_feat_list_50')\n",
    "accuracy_list_nas_75_mrmr, f1_score_list_nas_75_mrmr, auc_list_nas_75_mrmr = model_train_predict('mrmr_feat_list_75')\n",
    "accuracy_list_nas_90_mrmr, f1_score_list_nas_90_mrmr, auc_list_nas_90_mrmr = model_train_predict('mrmr_feat_list_90')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MI and mRMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list_nas_10_mi_mrmr, f1_score_list_nas_10_mi_mrmr, auc_list_nas_10_mi_mrmr = model_train_predict('mi_mrmr_feat_list_10*')\n",
    "accuracy_list_nas_20_mi_mrmr, f1_score_list_nas_20_mi_mrmr, auc_list_nas_20_mi_mrmr = model_train_predict('mi_mrmr_feat_list_20*')\n",
    "accuracy_list_nas_30_mi_mrmr, f1_score_list_nas_30_mi_mrmr, auc_list_nas_30_mi_mrmr = model_train_predict('mi_mrmr_feat_list_30*')\n",
    "accuracy_list_nas_50_mi_mrmr, f1_score_list_nas_50_mi_mrmr, auc_list_nas_50_mi_mrmr = model_train_predict('mi_mrmr_feat_list_50*')\n",
    "accuracy_list_nas_75_mi_mrmr, f1_score_list_nas_75_mi_mrmr, auc_list_nas_75_mi_mrmr = model_train_predict('mi_mrmr_feat_list_75*')\n",
    "accuracy_list_nas_90_mi_mrmr, f1_score_list_nas_90_mi_mrmr, auc_list_nas_90_mi_mrmr = model_train_predict('mi_mrmr_feat_list_90*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_accuracy_list_nas_mi = (accuracy_list_nas_10_mi + accuracy_list_nas_20_mi + accuracy_list_nas_30_mi + accuracy_list_nas_50_mi + accuracy_list_nas_75_mi + accuracy_list_nas_90_mi)\n",
    "overall_accuracy_list_nas_mrmr = (accuracy_list_nas_10_mrmr + accuracy_list_nas_20_mrmr + accuracy_list_nas_30_mrmr + accuracy_list_nas_50_mrmr + accuracy_list_nas_75_mrmr + accuracy_list_nas_90_mrmr)\n",
    "overall_accuracy_list_nas_mi_mrmr = (accuracy_list_nas_10_mi_mrmr + accuracy_list_nas_20_mi_mrmr + accuracy_list_nas_30_mi_mrmr + accuracy_list_nas_50_mi_mrmr + accuracy_list_nas_75_mi_mrmr + accuracy_list_nas_90_mi_mrmr)\n",
    "\n",
    "overall_f1_score_list_nas_mi = (f1_score_list_nas_10_mi + f1_score_list_nas_20_mi + f1_score_list_nas_30_mi + f1_score_list_nas_50_mi + f1_score_list_nas_75_mi + f1_score_list_nas_90_mi)\n",
    "overall_f1_score_list_nas_mrmr = (f1_score_list_nas_10_mrmr + f1_score_list_nas_20_mrmr + f1_score_list_nas_30_mrmr + f1_score_list_nas_50_mrmr + f1_score_list_nas_75_mrmr + f1_score_list_nas_90_mrmr)\n",
    "overall_f1_score_list_nas_mi_mrmr = (f1_score_list_nas_10_mi_mrmr + f1_score_list_nas_20_mi_mrmr + f1_score_list_nas_30_mi_mrmr + f1_score_list_nas_50_mi_mrmr + f1_score_list_nas_75_mi_mrmr + f1_score_list_nas_90_mi_mrmr)\n",
    "\n",
    "overall_auc_list_nas_mi = (auc_list_nas_10_mi + auc_list_nas_20_mi + auc_list_nas_30_mi + auc_list_nas_50_mi + auc_list_nas_75_mi + auc_list_nas_90_mi)\n",
    "overall_auc_list_nas_mrmr = (auc_list_nas_10_mrmr + auc_list_nas_20_mrmr + auc_list_nas_30_mrmr + auc_list_nas_50_mrmr + auc_list_nas_75_mrmr + auc_list_nas_90_mrmr)\n",
    "overall_auc_list_nas_mi_mrmr = (auc_list_nas_10_mi_mrmr + auc_list_nas_20_mi_mrmr + auc_list_nas_30_mi_mrmr + auc_list_nas_50_mi_mrmr + auc_list_nas_75_mi_mrmr + auc_list_nas_90_mi_mrmr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['nas'] * 60\n",
    "percentiles = ['10', '20', '30', '50', '75', '90'] * 10\n",
    "filename_sample_list = filename_sample_list * 6\n",
    "\n",
    "print(len(models))\n",
    "print(len(percentiles))\n",
    "print(len(filename_sample_list))\n",
    "print(len(overall_accuracy_list_nas_mi_mrmr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dictionary = {\n",
    "    'samples': filename_sample_list,\n",
    "    'models': models,\n",
    "    'percentiles': percentiles,\n",
    "    'mi_accuracy': overall_accuracy_list_nas_mi,\n",
    "    'mi_f1_score': overall_f1_score_list_nas_mi,\n",
    "    'mi_auc': overall_auc_list_nas_mi,\n",
    "    'mrmr_accuracy': overall_accuracy_list_nas_mrmr,\n",
    "    'mrmr_f1_score': overall_f1_score_list_nas_mrmr,\n",
    "    'mrmr_auc': overall_auc_list_nas_mrmr,\n",
    "    'mi_mrmr_accuracy': overall_accuracy_list_nas_mi_mrmr,\n",
    "    'mi_mrmr_f1_score': overall_f1_score_list_nas_mi_mrmr,\n",
    "    'mi_mrmr_auc': overall_auc_list_nas_mi_mrmr,\n",
    "}\n",
    "results_df = pd.DataFrame(results_dictionary)\n",
    "results_df.to_csv('overall_results_20_nas_{}.csv'.format(length_text), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local",
   "language": "python",
   "name": "local"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
